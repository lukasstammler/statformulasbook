[["index.html", "Formeln Statistik Kapitel 1 Vorbemerkung", " Formeln Statistik Lukas Stammler 2022-04-11 Kapitel 1 Vorbemerkung Formeln haben erfahrungsgemäss abschreckende Wirkung auf Studierende, die im Rahmen ihrer Grundausbildung einen Statistikkurs belegen müssen. Aus diesem Grund verzichte ich in den Unterrichtsmaterialien weitgehend darauf. Dieses Dokument fasst die wichtigsten Definitionen und Formeln für Studierende, die an einem Grundkurs Statistik teilnehmen, zusammen. Für das Verständnis der mathematischen Mechanismen hinter den statistischen Prinzipien, halte ich die Auseinandersetzung mit den Formeln für unabdingbar. Die Formeln werden durch Beispiele in R (R Core Team 2022) ergänzt, um ihre Anwendung zu illustrieren und in die Statistiksoftware einzuführen. Wie immer bin ich dankbar für Kommentare, Ergänzungen und Hinweise auf Fehler an lukas.stammler@bfh.ch. Lukas Stammler Frühjahr 2022 Referenzen "],["Deskriptive.html", "Kapitel 2 Deskriptive Statistik 2.1 Kennzahlen der zentralen Tendenz und der Streuung 2.2 Grafiken", " Kapitel 2 Deskriptive Statistik 2.1 Kennzahlen der zentralen Tendenz und der Streuung 2.1.1 Umfang \\(n\\) = Stichprobenumfang \\(N\\) = Umfang der Population 2.1.2 Arithmetisches Mittel, Mittelwert \\(\\bar{x}\\) = Stichprobenmittelwert \\(\\mu\\) = Populationsmittelwert \\[\\begin{equation} \\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n} \\tag{2.1} \\end{equation}\\] mit \\(x_j:\\) Messwert der i-ten Beobachtungseinheit in der Stichprobe \\(n:\\) Anzahl der Beobachtungseinheiten x &lt;- c(2, 3, 4, 4, 5, 6) # Beispieldaten in Variable x speichern n &lt;- length(x) # Anzahl Beobachtungseinheiten n sum(x)/n # Mittelwert berechnen ## [1] 4 mean(x) # R-Funktion ## [1] 4 2.1.3 Median wenn \\(n\\) ungerade \\[\\begin{equation} \\tilde{x} = x_{\\frac{n+1}{2}} \\tag{2.2} \\end{equation}\\] wenn \\(n\\) gerade \\[\\begin{equation} \\tilde{x} = \\frac{1}{2}(x_{\\frac{n}{2}} + {x_{\\frac{n}{2}+1}}) \\tag{2.3} \\end{equation}\\] Beispiel: x &lt;- c(2, 3, 4, 4, 5, 6, 10) # Beispieldaten in Variable x speichern median(x) # R-Funktion ## [1] 4 2.1.4 Varianz \\(s^2\\) = Stichprobenvarianz \\(\\sigma^2\\) = Varianz der Population Berechnung der Varianz in der Stichprobe zur Schätzung der Populationsvarianz \\[\\begin{equation} s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1} \\tag{2.4} \\end{equation}\\] Berechnung der Varianz in der Population \\[\\begin{equation} \\sigma^2 = \\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{n} \\tag{2.5} \\end{equation}\\] x &lt;- c(2, 3, 4, 4, 5, 6, 10) # Beispieldaten für eine Stichprobe n &lt;- length(x) # Stichprobenumfang n m &lt;- mean(x) # Mittelwert von x berechnen sum((x - m)^2)/(n - 1) # Varianz berechnen ## [1] 6.809524 var(x) # R-Funktion ## [1] 6.809524 2.1.5 Standardabweichung \\(s\\) = Standardabweichung der Stichprobe \\(\\sigma\\) = Standardabweichung der Population Berechnung der Standardabweichung für eine Stichprobe \\[\\begin{equation} s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}} \\tag{2.6} \\end{equation}\\] Berechnung der Standardabweichung für eine Population \\[\\begin{equation} \\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{n}} \\tag{2.7} \\end{equation}\\] x &lt;- c(2, 3, 4, 4, 5, 6, 10) # Beispieldaten für eine Stichprobe n &lt;- length(x) # Stichprobenumfang n m &lt;- mean(x) # Mittelwert von x berechnen varianz &lt;- sum((x - m)^2)/(n - 1) # Varianz berechnen sqrt(varianz) # Standardabweichung als Quadratwurzel der Varianz ## [1] 2.609506 sd(x) # R-Funktion ## [1] 2.609506 2.1.6 Minimum, Maximum und Variationsbreite x &lt;- c(2, 3, 4, 4, 5, 6, 10) # Beispieldaten für eine Stichprobe min(x) # Minimum der Variablen x ## [1] 2 max(x) # Maximum der Variablen x ## [1] 10 max(x) - min(x) # Variationsbreite der Variablen x ## [1] 8 2.2 Grafiken Auf Grund der Flexibilität wird der Code für Grafiken im Ggplot-Format (Wickham et al. 2021) angegeben. Um die Grafiken in R zu reproduzieren muss package ggplot2 installiert und geladen sein. install.packages(&quot;ggplot2&quot;) # ggplot2 package installieren (einmalig) library(ggplot2) # ggplot2 library laden 2.2.1 Histogramm Voraussetzung: Daten sind quantitativ # Beispieldatensatz mit Zufallszahlen aus Normalverteilung erzeugen set.seed(1111) daten &lt;- data.frame( Werte &lt;- rnorm(100, mean = 10, sd = 3) ) # einfaches Histogramm ggplot(data = daten, aes(x = Werte)) + geom_histogram() + xlab(&quot;Werte&quot;) + ylab(&quot;Anzahl&quot;) + ggtitle(&quot;Mein erstes Histogramm&quot;, subtitle = &quot;100 Werte aus N(M = 10, s = 3)&quot;) Figure 2.1: Ein Histogramm mit ggplot2 library(kableExtra) options(knitr.table.format = &quot;latex&quot;) # Klassenbreite auf 2 anpassen und Balken mit weissen Linien trennen ggplot(data = daten, aes(x = Werte)) + geom_histogram(binwidth = 2, color = &quot;white&quot;) + xlab(&quot;Werte&quot;) + ylab(&quot;Anzahl&quot;) + ggtitle(&quot;Mein zweites Histogramm&quot;, subtitle = &quot;100 Werte aus N(M = 10, s = 3)&quot;) Figure 2.2: Noch ein Histogramm mit ggplot2 Für weitere Details siehe z.B. The R Graph Gallery 2.2.2 Boxplot Voraussetzung: Daten sind quantitativ # Beispieldatensatz mit Zufallszahlen aus Normalverteilung erzeugen set.seed(1234) daten &lt;- data.frame( Werte &lt;- rnorm(100, mean = 10, sd = 3) ) ggplot(data = daten, aes(y = Werte)) + geom_boxplot() + ggtitle(&quot;Mein erster Boxplot&quot;, subtitle = &quot;100 Werte aus N(M = 10, s = 3)&quot;) Figure 2.3: Ein Boxplot mit ggplot2 Boxplots eignen sich gut für den Vergleich von Gruppen. # Beispieldatensatz für Körpergrösse von Frauen und Männerenerzeugen set.seed(1234) daten &lt;- data.frame( Geschlecht &lt;- c(rep(&quot;w&quot;, 50), rep(&quot;m&quot;, 50)), Groesse &lt;- c(rnorm(50, mean = 165, sd = 6), rnorm(50, 178, 7)) ) ggplot(data = daten, aes(y = Groesse, x = Geschlecht)) + geom_boxplot() + ylab(&quot;Groesse in cm&quot;) + ggtitle(&quot;Körpergrösse von Frauen und Männern&quot;, subtitle = &quot;n = 50 pro Geschlecht&quot;) Figure 2.4: Gruppierter Boxplot mit ggplot2 Für weitere Details siehe z.B. The R Graph Gallery 2.2.3 Balkendiagramm Voraussetzung: Daten sind qualitativ # Beispieldatensatz für Augenfarben von 50 Personen daten &lt;- data.frame( Augenfarbe &lt;- c(rep(&quot;blau&quot;, 20), rep(&quot;braun&quot;, 18), rep(&quot;grün&quot;, 12)) ) ggplot(data = daten, aes(x = Augenfarbe)) + geom_bar() + ylab(&quot;Anzahl&quot;) + ggtitle(&quot;Augenfarben, n = 50&quot;) Figure 2.5: Balkendiagramm mit ggplot2 Balken können z.B. eingefärbt werden (R verfügt über 657 Farben, siehe z.B. hier ) ggplot(data = daten, aes(x = Augenfarbe)) + geom_bar(fill = c(&quot;blue&quot;, &quot;brown&quot;, &quot;green&quot;)) + ylab(&quot;Anzahl&quot;) + ggtitle(&quot;Augenfarben, n = 50&quot;) Figure 2.6: Hübsches Balkendiagramm mit ggplot2 Für weitere Details siehe z.B. The R Graph Gallery 2.2.4 Tabellen für Häufigkeiten Tabelle mit absoluten Häufigkeiten für die Augenfarben erstellen. table(daten$Augenfarbe) ## ## blau braun grün ## 20 18 12 Tabelle mit den relativen Häufigkeiten für die Augenfarben erstellen. prop.table(table(daten$Augenfarbe)) ## ## blau braun grün ## 0.40 0.36 0.24 Referenzen "],["grundbegriffe-der-wahrscheinlichkeitstheorie.html", "Kapitel 3 Grundbegriffe der Wahrscheinlichkeitstheorie 3.1 Wahrscheinlichkeit 3.2 Ereignis und Komplementärereignis 3.3 Disjunkte Ereignisse 3.4 Nicht-disjunkte Ereignisse 3.5 Bedingte Wahrscheinlichkeiten 3.6 Unabhängigkeit 3.7 Theorem von Bayes", " Kapitel 3 Grundbegriffe der Wahrscheinlichkeitstheorie 3.1 Wahrscheinlichkeit Unter Wahrscheinlichkeit versteht man die Chance, dass bei einem Zufallsexperiment ein bestimmtes Ereignis auftritt. Wahrscheinlichkeiten können nur Werte zwischen 0 (unmögliches Ereignis) und 1 (sicheres Ereignis) zugeordnet werden. Nach Laplace ist die Wahrscheinlichkeit für ein günstiges Ereignis \\(p(A)\\): \\[\\begin{equation} p(A) = \\frac{n_A}{N_{gesamt}} = \\frac{Anzahl~der~günstigen~Ereignisse}{Anzahl~der~möglichen~Ereignisse} \\tag{3.1} \\end{equation}\\] 3.2 Ereignis und Komplementärereignis \\[\\begin{equation} p(A) + p(Nicht~A) = 1 \\tag{3.2} \\end{equation}\\] 3.3 Disjunkte Ereignisse Zwei Ereignisse A und B werden als disjunkt bezeichnet, wenn sie einander ausschliessen, d.h. dass A und B nicht gleichzeitig eintreffen können. \\[\\begin{equation} A \\cap B = 0 \\tag{3.3} \\end{equation}\\] Lese die Formel: Zwei Ereignisse A und B sind disjunkt, wenn die Schnittmenge der leeren Menge entspricht. 3.4 Nicht-disjunkte Ereignisse Zwei Ereignisse A und B werden als nicht-disjunkt bezeichnet, wenn die Wahrscheinlichkeit für das gleichzeitige Auftreten deser Ereignisse nicht gleich null ist. \\[\\begin{equation} A \\cap B \\neq 0 \\tag{3.3} \\end{equation}\\] Lese die Formel: Nicht-disjunkte Ereignisse haben eine nicht leere Schnittmenge. 3.5 Bedingte Wahrscheinlichkeiten Die bedingte Wahrscheinlichkeit \\(p(A|B)\\) quantifiziert die Wahrscheinlichkeit des Ereignisses A unter der Bedingung, dass das Ereignis B eingetreten ist. \\[\\begin{equation} p(A|B) = \\frac{p(A \\cap B)}{P(B)} \\tag{3.4} \\end{equation}\\] Das Zeichen \\(\\cap\\) ist das mathematische Symbol für UND (Schnittmenge von A und B). 3.6 Unabhängigkeit Zwei Ereignisse \\(A\\) und \\(B\\) sind unabhängig, wenn das Eintreffen oder Nicht-Eintreffen des Ereignisses \\(B\\) die Wahrscheinlichkeit für ein Ereignis \\(A\\) nicht verändert. \\[\\begin{equation} p(A) = p(A|B) ~, ~p(B) = p(B|A) \\tag{3.5} \\end{equation}\\] 3.7 Theorem von Bayes Das Theorem von Bayes gibt an, wie man eine bedingte Wahrscheinlichkeit \\(p(A|B)\\) aus der umgekehrten bedingten Wahrscheinlichkeit \\(p(B|A)\\) berechnen kann. \\[\\begin{equation} p(A|B)= \\frac{p(A) \\times p(B|A)}{p(B)} \\tag{3.6} \\end{equation}\\] "],["wahrscheinlichkeitsverteilungen.html", "Kapitel 4 Wahrscheinlichkeitsverteilungen 4.1 Binomialverteilung 4.2 Normalverteilung 4.3 T-Verteilung", " Kapitel 4 Wahrscheinlichkeitsverteilungen Diskrete Wahrscheinlichkeitsverteilung Die Ergebnisse eines Zufallsexperiments mit einer diskreten Variablen sind abzählbar bzw. können kategorisiert werden. Beispielsweise ist es beim Werfen eines Würfels nur möglich eine Zahl aus der Menge \\(X = {1, 2, 3, 4, 5, 6}\\) zu werfen. Der Wurf einer 2.6 ist jedoch nicht möglich. Die Anzahl der Seiten eines Würfels könnten gezählt und kategorisiert werden. Daher handelt es sich hierbei um eine diskrete Verteilung (Leonhart 2013). Kontinuierliche (= stetige) Wahrscheinlichkeitsverteilung Stetige Wahrscheinlichkeitsfunktionen beschreiben die Ergebnisse eines Zufallsexperiments, in dem unendlich viele Elementarereignisse realisiert werden können. So entsteht eine stetige Dichtefunktion der Wahrscheinlichkeitsverteilung (Leonhart 2013). Die Betrachtung eines einzelnen Ereignisses in einer stetigen Wahrscheinlichkeitsverteilung ist nicht sinnvoll, da die Wahrscheinlichkeit für ein Elementarereignis immer gegen null geht. Es ist sehr unwahrscheinlich, dass eine Studentin mit genau 167.793 cm Grösse an einer Lehrveranstaltung teilnimmt. Deshalb wir die Wahrscheinlichkeit für Intervalle zwischen zwei Elementarereignissen bestimmt. Diese Wahrscheinlichkeit entspricht der Fläche (dem Integral) der Dichtefunktion der stetigen Wahrscheinlichkeitsverteilung in diesen Grenzen (Leonhart 2013). 4.1 Binomialverteilung Die Binomialverteilung beschreibt die Auftretenswahrscheinlichkeit zweier alternativer Ereignisse. Sie wird durch einen Bernoulli-Prozess erzeugt. Dies ist eine Folge voneinander unabhängiger Ereignisse mit jeweils zwei möglichen Ausgängen. Die Wahrscheinlichkeiten für die einzelnen Ereignisse sind jeweils konstant (\\(p\\) bzw. \\(q = 1 - p\\)) (Leonhart 2013). 4.1.1 Voraussetzungen Die Versuche müssen unabhängig sein. Die Anzahl der Versuche muss bekannt sein. Jedes Versuchsergebnis ist entweder ein Erfolg oder ein Misserfolg. Die Wahrscheinlichkeit für einen Erfolg muss für jeden Versuch gleich sein. 4.1.2 Funktion der Binomialverteilung Die Funktion der Binomialverteilung beschreibt die Wahrscheinlichkeit des \\(k\\)-maligen Eintreffens eines Ereignisses X bei \\(n\\) Ereignissen Wenn \\(p\\) die Wahrscheinlichkeit für einen Erfolg ist, ist \\(1-p\\) die Wahrscheinlichkeit für einen Misserfolg. \\(n\\) gibt die Anzahl der Versuche an und \\(k\\) die Anzahl der Erfolge. \\[\\begin{equation} p(k, n) = {n \\choose k}p^k(1-p)^{n-k} \\tag{4.1} \\end{equation}\\] Die Gleichung setzt sich aus drei Faktoren zusammen: \\(n \\choose k\\) (sprich n über k) gibt die Anzahl aller möglichen Reihenfolgen an, die zu dem erwünschten Ereignis führen. Dieser Faktor wird als Binomialkoeffizient bezeichnet. \\(p^k\\) ist die Wahrscheinlichkeit für das k-malige Eintreten eines Erfolgs. \\((1-p)^{n-k}\\) ist die Wahrscheinlichkeit für das \\((n-k)\\)-malige Eintreffen des Komplementärereignisses. Wahrscheinlichkeit für \\(k\\) Erfolge in \\(n\\) Versuchen mit der Erfolgswahrscheinlichkeit \\(p\\) in R berechnen: # R: Dichtefunktion der Binomialverteilung dbinom(k, n, p) Beispiel: Wie gross ist die Wahrscheinlichkeit, bei drei Mal würfeln (\\(n\\) = 3), 1 bis 3 mal (\\(k\\) = 0 bis 3) eine bestimmte Zahl, z.B. eine 6 (\\(p\\) = 1/6) zu werfen? p &lt;- 1/6 n &lt;- 3 k &lt;- 1:3 dbinom(k, size = n, prob = p) ## [1] 0.34722222 0.06944444 0.00462963 4.1.3 Binomialkoeffizient Der Binomialkoeffizient gibt an, auf wie viele verschiedene Arten man \\(k\\) Objekte aus einer Menge von \\(n\\) verschiedenen Objekten auswählen kann. Anzahl Kombinationen von \\(k\\) Erfolgen in \\(n\\) Versuchen berechnen \\[\\begin{equation} {n \\choose k} = \\frac{n!}{k!(n-k)!} \\tag{4.2} \\end{equation}\\] # R: Binomialkoeffizient choose(n, k) Beispiel: Wieviele mögliche Kombinationen gibt es im Schweizer Zahlenlotto für 6 (= \\(k\\)) aus 42 (=\\(n\\)). choose(n = 42, k = 6) ## [1] 5245786 Es gibt \\(5245786\\) Kombinationen, d.h. die Wahrscheinlichkeit, 6 Richtige zu wählen beträgt 1\\(/5245786\\) = \\(0.0000002\\). 4.1.4 Eigenschaften der Binomialverteilung \\[\\begin{equation} X \\sim Bin(n, p) \\tag{4.3} \\end{equation}\\] \\(n\\) = Anzahl Versuche \\(p\\) = Eintrittswahrscheinlichkeit Erwartungswert (Mittelwert) der Binomialverteilung \\[\\begin{equation} \\mu = n \\times p \\tag{4.4} \\end{equation}\\] Standardabweichung der Binomialverteilung \\[\\begin{equation} \\sigma = \\sqrt{np(1-p)} \\tag{4.5} \\end{equation}\\] 4.1.5 Normalapproximation Eine Binomialverteilung mit mindestens 10 erwarteten Erfolgen und mindestens 10 erwarteten Misserfolgen folgt annähernd einer Normalverteilung. \\[n \\times p \\times (1-p) \\geq 10\\] Falls diese Bedingung erfüllt ist, gilt: \\[\\begin{equation} Bin(n, p) \\sim N(\\mu, \\sigma) \\tag{4.6} \\end{equation}\\] 4.2 Normalverteilung \\[\\begin{equation} X \\sim N(\\mu, \\sigma) \\tag{4.7} \\end{equation}\\] 4.2.1 68-95-99.7-Regel 68% in \\(\\mu \\pm 1\\sigma\\) 95% in \\(\\mu \\pm 2\\sigma\\), genauer \\(\\mu \\pm 1.96\\sigma\\) 99.7% in \\(\\mu \\pm 3\\sigma\\) 4.2.2 Standardnormalverteilung \\[\\begin{equation} X \\sim N(0, 1) \\tag{4.8} \\end{equation}\\] 4.2.3 z-Wert Der z-Wert einer Beobachtung \\(x_i\\) gibt an, um wieviele Standardabweichungen die Beobachtung über oder unter dem Mittelwert liegt. \\[\\begin{equation} z = \\frac{x_i-\\bar{x}}{s} \\tag{4.9} \\end{equation}\\] Der z-Wert des Mittelwerts ist 0. Ungewöhnliche Beobachtungen haben typischerweise einen z-Wert von \\(|z|&gt;2\\). 4.2.4 Wahrscheinlichkeiten und Perzentilen in R berechnen pnorm(x, mean, sd) # Fläche links von x 1 - pnorm(x, mean, sd) # Fläche rechts von x pnorm(x, mean, sd, lower.tail = FALSE) # Fläche rechts von x (alternativ) qnorm(percentile, mean, sd) # # Wert auf einer bestimmten Perzentile Beispiel: x &lt;- c(2, 3, 4, 4, 5, 6, 10, 9, 8, 7, 7, 7, 5, 4) mittelwert &lt;- mean(x) stdabw &lt;- sd(x) # Wahrscheinlichkeit für den Wert kleiner oder gleich 7 pnorm(7, mittelwert, stdabw) ## [1] 0.6991514 # Wahrscheinlichkeit für den Wert gleich oder grösser 7 1 - pnorm(7, mittelwert, stdabw) ## [1] 0.3008486 # Wert auf der 40%-Perzentile qnorm(.4, mittelwert, stdabw) ## [1] 5.19633 4.2.5 QQ-Plot Mittels QQ-Plots (Quantile-Quantile-Plots) können zwei Verteilungen grafisch verglichen werden, indem ihre Quantilen gegeneinander aufgetragen werden. Wenn die zwei Verteilungen exakt gleich sind, liegen die Punkte im QQ-Plot auf einer perfekten Linie. qqnorm() # QQ-Plot für Normalverteilung qqline() # Linie in QQ-Plot einzeichnen Beispiel: set.seed(1) x &lt;- rnorm(100) # simulation von 100 normalverteilten Werten, mean = 0, s = 1 qqnorm(x) # qq-plot erstellen qqline(x, col = &quot;blue&quot;) # Linie in qq-plot einzeichnen 4.3 T-Verteilung Die \\(T\\)-Verteilung kann als Variante der Normalverteilung aufgefasst werden. hat immer den Mittelwert 0. hat eine Standardabweichung, die vom Stichprobenumfang \\(n\\) abhängig ist. Wird nur durch einen einzigen Parameter, die Anzahl Freiheitsgrade \\(df\\) (engl. degrees of freedom), definiert. wird mit wachsendem \\(n\\) schmaler und geht für \\(n \\rightarrow \\infty\\) in die Normalverteilung über. \\[df = n-1\\] \\[t \\sim T(df)\\] Die \\(T\\)-verteilung wird verwendet, wenn der Stichprobenumfang klein ist (\\(n \\leq 30\\)) die Standardabweichung \\(\\sigma\\) der Population unbekannt ist und mit Hilfe der Stichprobenstandardabweichung \\(s\\) geschätzt werden muss. also eigentlich immer; die Software rechnet standardmässig mit der \\(T\\)-Verteilung. Die Teststatistik von \\(T\\)-Tests sind \\(t\\)-Werte. \\(t\\)-Werte werden gleich interpretiert wie \\(z\\)-Werte. Referenzen "],["grundlagen-der-inferenzstatistik.html", "Kapitel 5 Grundlagen der Inferenzstatistik 5.1 Schätzungen von Parametern 5.2 Hypothesentest für einen Mittelwert", " Kapitel 5 Grundlagen der Inferenzstatistik 5.1 Schätzungen von Parametern Wird zur Schätzung eines Populationsparameters nur eine Stichprobenkennzahl angegeben, so handelt es sich um eine Punktschätzung. Wird bei einer Schätzung neben der Kennzahl noch ein Konfidenzintervall bestimmt, in welchem mit einer bestimmten Wahrscheinlichkeit der Populationsparameter liegt, so handelt es sich um eine Intervallschätzung. 5.1.1 Schätzung bei qualitativen Merkmalen \\(p:\\) Stichprobenkennzahl \\(\\hat{p}:\\) Schätzer für den Populationsparameter \\(\\pi:\\) Populationsparameter Alle diese Kennzahlen können Werte zwischen 0 und 1 annehmen. Zentraler Grenzwertsatz für relative Häufigkeiten (engl. proportions) Relative Häufigkeiten von Stichproben sind annähernd normalverteilt mit ihrem Zentrum bei der Häufigkeit in der Population und einem Standardfehler, der umgekehrt proportional ist zum Stichprobenumfang. \\[\\begin{equation} \\hat{p} \\sim N \\lgroup Mittelwert = p, SE_p = \\sqrt{\\frac{p(1-p)}{n}} \\rgroup \\tag{5.1} \\end{equation}\\] Voraussetzungen Unabhängigkeit: Die Beobachtungen müssen voneinander unabhängig sein (Zufallsstichprobe) Stichprobenumfang: Es müssen mindestens 10 Erfolge und 10 Misserfolge vorliegen \\[\\begin{equation} n \\times p \\geq 10; ~n \\times (1-p) \\geq 10 \\tag{5.2} \\end{equation}\\] 95%-Konfidenzintervall für \\(\\pi\\) \\[\\begin{equation} CI_{95} = p \\pm z_{0.025} \\times SE_p \\tag{5.3} \\end{equation}\\] \\[\\begin{equation} SE_p = \\sqrt{\\frac{p(1 - p)}{n}} \\tag{5.4} \\end{equation}\\] Bei Intervallschätzung mit kleinen Stichproben (N &lt; 30, besser auch schon bei N &lt; 100) sollte statt der Standardnormalverteilung (\\(z\\)-Werte) die Verteilung der \\(t\\)-Werte zur Definition des Intervalls zugrunde gelegt werden (Leonhart 2013). \\[\\begin{equation} CI_{95} = p \\pm t_{0.025, df} \\times SE_p \\tag{5.5} \\end{equation}\\] Beispiel: Berechne die Wahrscheinlichkeit \\(P(\\hat{p} &gt; 0.95)\\) für ein Ereignis mit der Erfolgswahrscheinlichkeit \\(p\\) = 0.9 und einen Stichprobenumfang \\(n\\) = 200. # Für diesen Code müssen folgende Bibliotheken geladen werden ------------------ # library(dplyr) # library(knitr) # library(kableExtra) # Voraussetzungen prüfen ------------------------------------------------------- p.hat &lt;- .95 p &lt;- .9 n &lt;- 200 n * p # Anzahl Erfolge ## [1] 180 n * (1 - p) # Anzahl Misserfolge ## [1] 20 # Normalapproximation ---------------------------------------------------------- mean.p &lt;- p SE.p &lt;- sqrt((p * (1 - p))/n) # 95%-CI berechnen ------------------------------------------------------------- z &lt;- abs(qnorm(.025)) CI &lt;- mean.p + c(-1, 1) * z * SE.p # z-Wert berechnen ------------------------------------------------------------- z.p.hat &lt;- (p.hat - p)/SE.p # p-Wert berechnen ------------------------------------------------------------- prob &lt;- 1 - pnorm(z.p.hat) # Tabelle für Output erstellen ------------------------------------------------- result &lt;- tibble( n = n, p = p, p.hat = p.hat, SE.p = SE.p, CI.lo = CI[1], CI.up = CI[2], z = z.p.hat, prob = prob ) result %&gt;% kbl(digits = 5, caption = &quot;Wahrscheinlichkeit für p.hat &gt; 0.95 bei p = 0.9&quot;) %&gt;% kable_styling(full_width = FALSE) Table 5.1: Wahrscheinlichkeit für p.hat &gt; 0.95 bei p = 0.9 n p p.hat SE.p CI.lo CI.up z prob 200 0.9 0.95 0.02121 0.8584 0.9416 2.357 0.00921 Die Frage kann auch unter Verwendung der Binomialverteilung beantwortet werden: Die erwartete Wahrscheinlichkeit bei 200 Versuchen mit \\(p\\) = 0.95 ist \\(\\hat{p} = 200 \\times 0.95 = 190\\) Wie gross ist die Wahrscheinlichkeit für \\(p \\geq 190\\) bei 200 Stichproben und einer Wahrscheinlichkeit von \\(p\\) = 0.9 in der Population unter der Nullhypothese? # Wahrscheinlichkeit für 190 oder mehr Erfolge bei n = 200 und p = .9 sum(dbinom(190 : 200, size = 200, prob = .9)) ## [1] 0.008071 5.1.2 Schätzung bei quantitativen Merkmalen Zentraler Grenzwertsatz Die Verteilung von Stichprobenkennzahlen (z.B. Mittelwert) folgt annähernd einer Normalverteilung. Ihr Mittelwert liegt in der Nähe des Populationsmittelwertes \\(\\mu\\) mit einer Standardabweichung geteilt durch die Quadratwurzel des Stichprobenumfangs (Standardfehler \\(SE\\)). \\[\\begin{equation} \\bar{x} \\sim N(Mittelwert = \\mu, SE = \\frac{\\sigma}{\\sqrt{n}}) \\tag{5.6} \\end{equation}\\] Wenn \\(\\sigma\\) unbekannt ist (was eigentlich immer der Fall ist), wird die Standardabweichung \\(s\\) der Stichprobe als Schätzer für \\(\\sigma\\) eingesetzt. \\[\\begin{equation} SE = \\frac{s}{\\sqrt{n}} \\tag{5.7} \\end{equation}\\] Bedingungen für die Gültigkeit des zentralen Grenzwertsatzes: Die Beobachtungseinheiten in der Stichprobe sind unabhängig voneinander (zufällige Auswahl, zufällige Zuordnung zu Gruppen). Faustregel: Stichprobenumfang \\(n&gt;30\\) Beispiel für die Berechnung des Standardfehlers \\(SE\\) in R set.seed(1234) x &lt;- rnorm(100) # simulation von 100 normalverteilten Werten, mean = 0, s = 1 n &lt;- length(x) # Stichprobenumfang von x ermitteln s &lt;- sd(x) # Standardabweichung von x berechnen s/sqrt(n) # Berechnung und Ausgabe von SE ## [1] 0.1004 95%-Konfidenzintervall für \\(\\mu\\) Ein Konfidenzintervall bezieht sich immer auf einen Popultionsparameter, z.B. \\(\\mu\\) nicht auf eine Stichprobenkennzahl! Konfidenzintervalle (Vertrauensintervalle, \\(CI\\)) können auf jedem Konfidenzniveau berechnet werden. Um die Sache nicht allzu kompliziert zu machen, wird hier v.a. exemplarisch die Berechnung von 95%-Konfidenzinteravallen vorgestellt. Signifikanzniveau = \\(\\alpha\\) Konfidenzniveau = \\(1-\\alpha\\) \\[\\begin{equation} CI_{95} = \\bar{x} \\pm z_{\\frac{\\alpha}{2}} \\times SE \\tag{5.8} \\end{equation}\\] Allgemein formuliert: \\[\\begin{equation} CI_{1-\\alpha} = \\bar{x} \\pm z_{\\frac{\\alpha}{2}} \\times SE \\tag{5.8} \\end{equation}\\] \\[\\begin{equation} z_{\\frac{\\alpha}{2}} = \\vert \\frac{(1-CI_{1-\\alpha})}{2} \\vert \\tag{5.9} \\end{equation}\\] \\[\\begin{equation} ME = z_{\\frac{\\alpha}{2}} \\times SE = z_{\\frac{\\alpha}{2}} \\times \\frac{s}{\\sqrt{n}} \\tag{5.10} \\end{equation}\\] \\(z_{\\frac{\\alpha}{2}} \\times SE\\) wird auch als Fehlerbereich (engl. \\(margin~ of~ error,~ ME\\)) bezeichnet. Der Wert von \\(z_{\\frac{\\alpha}{2}}\\) ist abhängig vom Konfidenzniveau \\(1-\\alpha\\). # z für ein 95% CI CI &lt;- .95 alpha &lt;- 1 - CI z95 &lt;- abs(qnorm(alpha/2)) paste(&quot;CI-Niveau = &quot;, CI * 100, &quot;%, alpha = &quot;, alpha, &quot;, z = &quot;, round(z95, 3), sep = &quot;&quot;) ## [1] &quot;CI-Niveau = 95%, alpha = 0.05, z = 1.96&quot; # z für ein 90% CI CI &lt;- .9 alpha &lt;- 1 - CI z90 &lt;- abs(qnorm(alpha/2)) paste(&quot;CI-Niveau = &quot;, CI * 100, &quot;%, alpha = &quot;, alpha, &quot;, z = &quot;, round(z90, 3), sep = &quot;&quot;) ## [1] &quot;CI-Niveau = 90%, alpha = 0.1, z = 1.645&quot; # z für ein 99% CI CI &lt;- .99 alpha &lt;- 1 - CI z99 &lt;- abs(qnorm(alpha/2)) paste(&quot;CI-Niveau = &quot;, CI * 100, &quot;%, alpha = &quot;, alpha, &quot;, z = &quot;, round(z99, 3), sep = &quot;&quot;) ## [1] &quot;CI-Niveau = 99%, alpha = 0.01, z = 2.576&quot; Beispiel für die Berechnung eines 95% Konfidenzintervalls m &lt;- 95.6 # Stichprobenmittelwert s &lt;- 15.8 # Standardabweichung der Stichprobe n &lt;- 100 # Stichprobenumfang # gesucht ist das 95% Konfidenzintervall für den Populationsmittelwert CI &lt;- .95 # Konfidenzniveau 95% alpha &lt;- 1 - CI # Signifikanzniveau alpha z &lt;- abs(qnorm(alpha/2)) ME &lt;- z * CI # Fehlerbereich berechnen # Obere und untere Grenze für 95%-Konfidenzintervall berechnen CI95 &lt;- m + c(-1, 1) * ME CI95 ## [1] 93.74 97.46 Zuverlässigkeit vs. Präzision einer Schätzung Der Standardfehler beschreibt die Präzisieon der Schätzung eines Parameters. Je mehr Werte in die Schätzung eingehen, umso kleiner wird wird der Standardfehler. Je kleiner der Standardfehler, desto präziser die Schätzung. Wenn wir das Konfidenzniveau erhöhen (Konfidenzintervall wird breiter, z.B. von 95% auf 99%) nimmt die Zuverlässigkeit, dass wir den wahren Populationsparameter im Intervall haben zu, allerdings auf Kosten der Präzision. Durch Erhöhung des Stichprobenumfangs kann die Zuverlässigkeit und die Präzision gleichzeitig verbessert werden. Stichprobenumfang für einen bestimmten Fehlerbereich berechnen: \\[\\begin{equation} ME = z^* \\times \\frac{s}{\\sqrt{n}} \\rightarrow n = (\\frac{z^* \\times s}{ME})^2 \\tag{5.11} \\end{equation}\\] ME.alt &lt;- 1.862 ME.neu &lt;- ME.alt/2 # neues 95%-Konfidenzintervall berechnen CI95.neu &lt;- m + c(-1, 1) * ME.neu print(paste(&quot;CI95 neu [&quot;, CI95.neu[1], &quot;,&quot;, CI95.neu[2], &quot;]&quot;)) ## [1] &quot;CI95 neu [ 94.669 , 96.531 ]&quot; # Stichprobenumfang für das neue 95%-CI berechnen n.neu &lt;- ((z * s)/ME.neu)^2 print(paste(&quot;Stichprobenumfang neu:&quot;, n.neu)) ## [1] &quot;Stichprobenumfang neu: 1106.39701140001&quot; 5.2 Hypothesentest für einen Mittelwert Hypothesentests werden immer für einen Popultionsparameter, z.B. \\(\\mu\\) durchgeführt und nicht für eine Stichprobe! 5.2.1 Vorgehen Formuliere die wissenschaftliche Hypothese \\(H_0: \\mu = Nullwert\\) \\(H_A: \\mu &lt; oder &gt; oder \\neq Nullwert\\) Es wird empfohlen \\(H_A:\\) immer zweiseitig formulieren ausser in begründeten Ausnahmefällen. Berechne den Punktschätzer \\(\\bar{x}\\) für \\(\\mu\\) Überprüfe die Testvoraussetzungen Beobachtungseinheiten in der Stichprobe sind unabhängig. Stichprobe stammt aus eine annähernd normalverteilten Population. Der Stichprobenumfang \\(n \\geq 30\\) oder grösser bei stark schiefer Verteilung. Skizziere die Stichprobenverteilung, zeichne deinen Verwerfungsbereich ein und berechne die Teststatistik. \\[\\begin{equation} z = \\frac{\\bar{x} - \\mu}{SE}, ~~ SE = \\frac{s}{\\sqrt{n}} \\tag{5.12} \\end{equation}\\] Berechne den kritischen \\(z\\)-Wert für ein bestimmtes Signifikanzniveau \\(\\alpha\\). \\[\\begin{equation} z_{krit} = \\pm |z_{\\frac{1-\\alpha}{2}}| \\tag{5.13} \\end{equation}\\] Liegt \\(z\\) im Verwerfungsbereich wird \\(H_0\\) zu Gunsten von \\(H_A\\) zurückgewiesen. Interpretiere das Resultat im Zusammenhang mit der Fragestellung. 5.2.2 p-Werte berechnen Definition: \\[\\begin{equation} p-Wert = P(beobachtete~oder~extremere~Teststatistik~ | ~H_0~ wahr) \\tag{5.14} \\end{equation}\\] Der p-Wert quantifiziert die Evidenz gegen \\(H_0\\). Ein kleiner \\(p\\)-Wert (üblicherweise \\(p \\leq 0.05\\)) bedeutet, dass du ausreichend Evidenz dafür hast, \\(H_0\\) zu Gunsten von \\(H_A\\) zu verwerfen. Einseitiger Hypothesentest anhand von p-Werten Fall \\[H_0: \\mu = Nullwert\\] \\[H_A: \\mu &gt; Nullwert\\] \\[\\begin{equation} z = \\frac{\\bar{x}-Nullwert}{SE_{\\bar{x}}} \\tag{5.15} \\end{equation}\\] \\(p\\)-Wert in R berechnen: p &lt;- 1 - pnorm(z) Figure 5.1: 5%-Verwerfungsbereich für \\(\\mu\\) &gt; Nullwert Fall \\[H_0: \\mu = Nullwert\\] \\[H_A: \\mu &lt; Nullwert\\] \\[\\begin{equation} z = \\frac{\\bar{x}-Nullwert}{SE_{\\bar{x}}} \\tag{5.16} \\end{equation}\\] \\(p\\)-Wert in R berechnen: p &lt;- pnorm(z) Figure 5.2: 5%-Verwerfungsbereich für \\(\\mu\\) &lt; Nullwert Zweiseitiger Hypothesentest anhand von p-Werten Zweiseitige Hypothesen sind der Normalfall. Einseitige Hypothesen sollten nur in begründeten Ausnahmefällen formuliert werden. \\[H_0: \\mu = Nullwert\\] \\[H_A: \\mu \\neq Nullvalue\\] \\[\\begin{equation} z = \\frac{\\bar{x}-Nullwert}{SE_{\\bar{x}}} \\tag{5.17} \\end{equation}\\] \\(p\\)-Wert in R berechnen: p &lt;- 2 * pnorm(abs(z), lower.tail = FALSE) # Alternative p &lt;- 2 * pnorm(-abs(z)) Figure 5.3: 5%-Verwerfungsbereiche für \\(\\mu \\neq\\) Nullwert 5.2.3 Entscheidungsfehler Fehler 1. Art: \\(H_0\\) wird verworfen wenn \\(H_0\\) wahr ist. Fehler 2. Art: \\(H_0\\) wird nicht verworfen wenn \\(H_A\\) wahr ist. Bei einem Signifikanzniveau \\(\\alpha = 0.05\\) nehmen wir ein Risiko von 5% in Kauf, einen Fehler 1. Art zu begehen. \\(\\alpha:\\) Wahrscheinlichkeit, einen Fehler 1. Art zu begehen. \\(\\beta:\\) Wahrscheinlichkeit, einen Fehler 2. Art zu begehen. \\(1-\\beta:\\) Power (Trennschärfe) eines Tests; Wahrscheinlichkeit, für \\(H_A\\) zu entscheiden, wenn \\(H_A\\) wahr ist. 5.2.4 Hypothesentests mit Konfidenzintervallen Ein zweiseitiger Hypothesentest mit einem Signifikanzniveau \\(\\alpha\\) entspricht einem Konfidenzintervall mit dem Konfidenzniveau \\(1-\\alpha\\). Ein einseitiger Hypothesentest mit einem Signifikanzniveau \\(\\alpha\\) entspricht einem Vertrauensintervall mit einem Konfidenzniveau von \\(1-(2 \\times \\alpha)\\). Enthält ein 95% Vertrauensintervall den Nullwert nicht, wird \\(H_0\\) verworfen. Enthält ein 95% Vertrauensintervall den Nullwert, wird \\(H_0\\) nicht verworfen. 5.2.5 Vorgehen Hypothesen \\(H_0\\) und \\(H_A\\) formulieren. Signifikanzniveau \\(\\alpha\\) festlegen (meist \\(\\alpha\\) = 0.05). Voraussetzungen (Normalverteilung, Stichprobenumfang) für Testwahl prüfen. (1-\\(\\alpha\\))-Konfidenzintervall für Populationsparameter berechnen. Teststatistik berechnen. \\(p\\)-Wert für die Teststatisik berechnen. \\(p\\)-Wert mit Signifikanzniveau vergleichen und Entscheiden ob man \\(H_0\\) verwirft oder beibehält. Ergebnis in allgemein verständlicher Sprache formulieren. Referenzen "],["inferenz-für-quantitative-daten.html", "Kapitel 6 Inferenz für quantitative Daten 6.1 Parametrische Testverfahren 6.2 Nicht-parametrische Testverfahren 6.3 Bootstrap-Methode", " Kapitel 6 Inferenz für quantitative Daten 6.1 Parametrische Testverfahren Parametrische Testverfahren setzen voraus, dass das zu untersuchende Beobachtungsmerkmal aus einer eindeutig definierten Verteilung, meist aus einer Normalverteilung stammt. Übersicht zur Testwahl Voraussetzung: Beobachtungsmerkmal stammt aus einer normalverteilten Population. Eine Stichprobe \\(n &gt; 30 \\rightarrow\\) z-Test \\(n \\leq 30 \\rightarrow\\) Einstichproben-t-Test zwei Stichproben verbundene (abhängige) Stichproben \\(\\rightarrow\\) t-Test für verbundene Stichproben unabhängige Stichproben \\(\\rightarrow\\) t-Test für unabhängige Stichproben (Welch-Test) 6.1.1 z-Test Mit dem \\(z\\)-Test vergleichen wir den Mittelwert einer Stichprobe mit einem bekannten Populationsmittelwert (= Nullwert). Hypothesen \\(H_0\\) und \\(H_A\\) formulieren. \\(H_0: \\mu = Nullwert\\) \\(H_A: \\mu \\neq Nullwert\\) Signifikanzniveau \\(\\alpha\\) festlegen (meist \\(\\alpha\\) = 0.05). Voraussetzungen (Normalverteilung, Stichprobenumfang) für Testwahl prüfen. \\(n \\geq 30\\) Zufallsstichprobe Beobachtungsmerkmal muss quantitativ und annähernd normalverteilt sein. (1-\\(\\alpha\\))-Konfidenzintervall für Populationsparameter berechnen. \\[\\begin{equation} CI_{1-\\alpha} = \\bar{x} \\pm z_{\\frac{alpha}{2}} \\times SE_{\\bar{x}} \\tag{6.1} \\end{equation}\\] \\[\\begin{equation} SE_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\tag{6.2} \\end{equation}\\] # z für Berechnung des CI in R berechnen z &lt;- abs(qnorm(alpha/2)) Wenn der Nullwert nicht im (1 - \\(\\alpha\\)) Konfidenzintervall enthalten ist, ist der Unterschied zwischen \\(\\mu\\) und Nullwert statistisch signifikant. Teststatistik berechnen. \\[\\begin{equation} z = \\frac{\\bar{x} - Nullwert}{SE_{\\bar{x}}} \\tag{6.3} \\end{equation}\\] \\(p\\)-Wert für die Teststatistik berechnen. # p-Wert für eine zweiseitige Hypothese 2 * (1 - pnorm(abs(z))) # alternativ 2 * pnorm(-abs(z)) 2 * pnorm(abs(z), lower.tail = FALSE) \\(p\\)-Wert mit Signifikanzniveau vergleichen und Entscheiden ob man \\(H_0\\) verwirft oder beibehält. Ist der \\(p\\)-Wert kleiner als das Signifikanzniveau \\(\\alpha\\), wird die \\(H_0\\) zu Gunsten der \\(H_A\\) verworfen. Ergebnis in allgemein verständlicher Sprache formulieren. Beispiel: Bei 30 Personen wurde der Effekt eines Blutdruckmedikaments getestet. Der Hersteller gibt an, dass das Medikament den systolischen Blutdruck im Durchschnitt um 5 mmHg senkt. Der Effekt auf den systolischen Blutdruck wurde in der Variablen BDsys gespeichert. set.seed(1) BDsys &lt;- rnorm(30, mean = -6, sd = 4) # simulierte Daten generieren alpha &lt;- 0.05 # Signifikanzniveau festlegen # CI berechnen mean.BDsys &lt;- mean(BDsys) # Mittelwert für BDsys sd.BDsys &lt;- sd(BDsys) # Standardabweichung für BDsys n.BDsys &lt;- length(BDsys) # Stichprobenumfang für BDsys SE.BDsys &lt;- sd.BDsys / sqrt(n.BDsys) # SE für Mittelwert von BDsys z.CI &lt;- abs(qnorm(alpha / 2)) # z-Wert CI &lt;- mean.BDsys + c(-1, 1) * z.CI * SE.BDsys # Grenzen für CI berechnen CI &lt;- round(CI, 3) # Werte für CI auf 3 Stellen runden CI.output &lt;- paste((1 - alpha) * 100, &quot;%-CI [&quot;, CI[1], &quot;, &quot;, CI[2], &quot;]&quot;, sep = &quot;&quot;) print(CI.output) # CI ausgeben ## [1] &quot;95%-CI [-6.993, -4.347]&quot; # Teststatistik berechnen nullvalue &lt;- -5 # Nullwert eingeben z &lt;- (mean.BDsys - nullvalue)/SE.BDsys # z-Wert berechnen p &lt;- 2 * pnorm(-abs(z)) # p-Wert für z berechnen (zweiseitig) z &lt;- round(z, 3) # z auf 3 Stellen runden p &lt;- round(p, 4) # p-Wert auf 4 Stellen runden result &lt;- paste(&quot;z = &quot;, z, &quot;, p = &quot;, p, sep = &quot;&quot;) print(result) ## [1] &quot;z = -0.993, p = 0.3207&quot; Ergebnis in allgemein verständlicher Sprache formulieren: Die Einnahme des Blutdrucksenkers reduziert den systolischen Blutdruck im Durchschnitt um -5.67, 95%-CI [-6.993, -4.347] mmHg. Der vom Hersteller angegebene Wert von durchschnittlich -5 mmHg ist in diesem 95%-Konfidenzintervall enthalten und es liegt keine Evidenz gegen die Nullhypothese (\\(H_0: \\mu = -5\\)) vor, \\(z\\) = -0.993, \\(p\\) = 0.3207. Hinweis: Für den \\(z\\)-Test existiert keine Funktion in R-base. Zum Überprüfen der Ergebnisse kann die Funkion z.test() aus dem Package BSDA verwendet werden. install.packages(&quot;BSDA&quot;) library(BSDA) z.test() # für Beschreibung ?z.test eingeben 6.1.2 Einstichproben-\\(t\\)-Test Wie beim \\(z\\)-Test vergleichen wir den Mittelwert einer Stichprobe mit einem bekannten Populationsmittelwert (= Nullwert). Bei kleinen Stichproben (\\(n &lt; 30\\)) kann der \\(z\\)-Test allerdings nicht angewendet werden und wir verwenden den Einstichproben-\\(t\\)-Test. Merke: Statistikprogramme wie R verwenden immer den \\(t\\)-Test. Hypothesen \\(H_0\\) und \\(H_A\\) formulieren. \\(H_0: \\mu = Nullwert\\) \\(H_A: \\mu \\neq Nullwert\\) Signifikanzniveau \\(\\alpha\\) festlegen (meist \\(\\alpha\\) = 0.05). Voraussetzungen (Normalverteilung, Stichprobenumfang) für Testwahl prüfen. Zufallsstichprobe Beobachtungsmerkmal muss quantitativ und annähernd normalverteilt sein. (1-\\(\\alpha\\))-Konfidenzintervall für Populationsparameter berechnen. \\[\\begin{equation} CI_{1-\\alpha} = \\bar{x} \\pm t_{\\frac{\\alpha}{2},df} \\times SE_{\\bar{x}} \\tag{6.4} \\end{equation}\\] \\[\\begin{equation} SE_{\\bar{x}} = \\frac{s}{\\sqrt{n}}, ~~ df = n-1 \\tag{6.5} \\end{equation}\\] # t für Berechnung des CI in R berechnen t &lt;- abs(qt(alpha/2), df = n - 1) Wenn der Nullwert nicht im (1 - \\(\\alpha\\)) Konfidenzintervall enthalten ist, ist der Unterschied zwischen \\(\\mu\\) und Nullwert statistisch signifikant. Teststatistik berechnen. \\[\\begin{equation} t = \\frac{\\bar{x} - Nullwert}{SE_{\\bar{x}}} \\tag{6.6} \\end{equation}\\] \\(p\\)-Wert für die Teststatistik berechnen. # p-Wert für eine zweiseitige Hypothese 2 * (1 - pt(abs(t), df = n - 1 )) # alternativ 2 * pt(-abs(t), df = n - 1) 2 * pt(abs(t), , df = n - 1, lower.tail = FALSE) \\(p\\)-Wert mit Signifikanzniveau vergleichen und Entscheiden ob man \\(H_0\\) verwirft oder beibehält. Ist der \\(p\\)-Wert kleiner als das Signifikanzniveau \\(\\alpha\\), wird die \\(H_0\\) zu Gunsten der \\(H_A\\) verworfen. Ergebnis in allgemein verständlicher Sprache formulieren. Beispiel: Bei 12 Personen wurde der Effekt eines Blutdruckmedikaments getestet. Der Hersteller gibt an, dass das Medikament den systolischen Blutdruck im Durchschnitt um 5 mmHg senkt. Der Effekt auf den systolischen Blutdruck wurde in der Variablen BDsys gespeichert. set.seed(1) BDsys &lt;- rnorm(12, mean = -6, sd = 4) # simulierte Daten generieren alpha &lt;- 0.05 # Signifikanzniveau festlegen # CI berechnen mean.BDsys &lt;- mean(BDsys) # Mittelwert für BDsys sd.BDsys &lt;- sd(BDsys) # Standardabweichung für BDsys n.BDsys &lt;- length(BDsys) # Stichprobenumfang für BDsys SE.BDsys &lt;- sd.BDsys / sqrt(n.BDsys) # SE für Mittelwert von BDsys t.CI &lt;- abs(qt(alpha / 2, df = n.BDsys - 1)) # t-Wert CI &lt;- mean.BDsys + c(-1, 1) * t.CI * SE.BDsys # Grenzen für CI berechnen CI &lt;- round(CI, 3) # Werte für CI auf 3 Stellen runden CI.output &lt;- paste((1 - alpha) * 100, &quot;%-CI [&quot;, CI[1], &quot;, &quot;, CI[2], &quot;]&quot;, sep = &quot;&quot;) print(CI.output) # CI ausgeben ## [1] &quot;95%-CI [-6.986, -2.865]&quot; # Teststatistik berechnen nullvalue &lt;- -5 # Nullwert eingeben t &lt;- (mean.BDsys - nullvalue)/SE.BDsys # z-Wert berechnen p &lt;- 2 * pt(-abs(t), df = n.BDsys - 1) # p-Wert für z berechnen (zweiseitig) t &lt;- round(t, 4) # z auf 3 Stellen runden p &lt;- round(p, 4) # p-Wert auf 4 Stellen runden result &lt;- paste(&quot;t = &quot;, t, &quot;, p = &quot;, p, sep = &quot;&quot;) print(result) ## [1] &quot;t = 0.0796, p = 0.938&quot; Ergebnis in allgemein verständlicher Sprache formulieren: Die Einnahme des Blutdrucksenkers reduziert den systolischen Blutdruck im Durchschnitt um -4.925, 95%-CI [-6.986, -2.865] mmHg. Der vom Hersteller angegebene Wert von durchschnittlich -5 mmHg ist in diesem 95%-Konfidenzintervall enthalten und es liegt keine Evidenz gegen die Nullhypothese (\\(H_0: \\mu = -5\\)) vor, \\(t\\) = 0.0796, \\(df\\) = 11, \\(p\\) = 0.938. Einfacher geht es mit der R-Funktion t.test(). t.test(BDsys, mu = -5) ## ## One Sample t-test ## ## data: BDsys ## t = 0.08, df = 11, p-value = 0.9 ## alternative hypothesis: true mean is not equal to -5 ## 95 percent confidence interval: ## -6.986 -2.865 ## sample estimates: ## mean of x ## -4.925 6.1.3 t-Test für verbundene Stichproben Bei abhängigen Stichproben wird davon ausgegangen, dass die Messwerte in Paaren vorliegen, z.B. Gleiche Beobachtungseinheiten: Vorher-Nachher-Messungen, Messwiederholungen Unterschiedliche Beobachtungseinheiten (jedoch voneinander abhängig): Zwillingsstudien, Partner, matched pairs. Parameter: \\(\\mu_{\\Delta}\\) = Mittelwert der paarweisen Differenzen in der Population Punktschätzer: \\(\\bar{x}_{\\Delta}\\) = Mittelwert der paarweisen Differenzen in der Stichprobe Teststatistik: \\(t\\) Hypothesen \\(H_0\\) und \\(H_A\\) formulieren. \\(H_0: \\mu_{\\Delta} = 0\\) \\(H_A: \\mu_{\\Delta} \\neq 0\\) (zweiseitige \\(H_A\\)) Signifikanzniveau \\(\\alpha\\) festlegen (meist \\(\\alpha\\) = 0.05). Voraussetzungen (Normalverteilung, Stichprobenumfang) für Testwahl prüfen. Zufallsstichprobe Paarweise Differenzen sind annähernd normalverteilt. \\(n \\geq 12\\) oder grösser bei stark schiefen Verteilungen (1-\\(\\alpha\\))-Konfidenzintervall für Populationsparameter berechnen. \\[\\begin{equation} CI_{1-\\alpha} = \\bar{x}_{\\Delta} \\pm t_{\\frac{\\alpha}{2}, df} \\times SE_{\\bar{x}_{\\Delta}} \\tag{6.7} \\end{equation}\\] \\[\\begin{equation} SE_{\\bar{x}_{\\Delta}} = \\frac{s_{\\Delta}}{\\sqrt{n}}, ~~ df = n-1 \\tag{6.8} \\end{equation}\\] # t für Berechnung des CI in R berechnen t &lt;- abs(qt(alpha/2), df = n - 1) Teststatistik berechnen. \\[\\begin{equation} t = \\frac{\\bar{x}_{\\Delta} - 0}{SE_{\\bar{x}_{\\Delta}}} \\tag{6.9} \\end{equation}\\] \\(p\\)-Wert für die Teststatisik berechnen. # p-Wert für eine zweiseitige Hypothese 2 * (1 - pt(abs(t), df = n - 1 )) # alternativ 2 * pt(-abs(t), df = n - 1) 2 * pt(abs(t), , df = n - 1, lower.tail = FALSE) \\(p\\)-Wert mit Signifikanzniveau vergleichen und Entscheiden ob man \\(H_0\\) verwirft oder beibehält. Ist der \\(p\\)-Wert kleiner als das Signifikanzniveau \\(\\alpha\\), wird die \\(H_0\\) zu Gunsten der \\(H_A\\) verworfen. Ergebnis in allgemein verständlicher Sprache formulieren. Beispiel: Körpergewicht in kg für 17 Probandinnen vor und nach einer Anorexie Therapie. Hat die Therapie einen signifikanten Effekt? ## create dataset (data extracted &amp; converted from package PairedData::Anorexia) anorexia &lt;- data.frame( id = seq(from = 1, to = 17, by = 1), vor = c(38.0, 37.8, 39.0, 37.4, 39.3, 36.1, 34.9, 42.7, 33.3, 36.5, 37.0, 37.2, 35.2, 37.9, 40.8, 39.0, 39.6), nach = c(43.2, 42.8, 41.5, 41.7, 45.5, 34.8, 34.8, 46.1, 43.0, 34.1, 35.3, 43.3, 41.1, 42.0, 42.5, 41.6, 44.5) ) # erste 6 Beobachtungseinheiten im Datensatz anzeigen head(anorexia) ## id vor nach ## 1 1 38.0 43.2 ## 2 2 37.8 42.8 ## 3 3 39.0 41.5 ## 4 4 37.4 41.7 ## 5 5 39.3 45.5 ## 6 6 36.1 34.8 # paarweise Differenzen berechnen und in Variable anorexia$diff speichern anorexia$diff &lt;- anorexia$nach - anorexia$vor head(anorexia) ## id vor nach diff ## 1 1 38.0 43.2 5.2 ## 2 2 37.8 42.8 5.0 ## 3 3 39.0 41.5 2.5 ## 4 4 37.4 41.7 4.3 ## 5 5 39.3 45.5 6.2 ## 6 6 36.1 34.8 -1.3 ## Verteilung der paarweisen Differenzen prüfen -------------------------------- qqnorm(anorexia$diff) # QQ-Plot erstellen qqline(anorexia$diff) ## CI für anorexia$diff berechnen ---------------------------------------------- alpha &lt;- 0.05 # Signifikanzniveau festlegen mean.diff &lt;- mean(anorexia$diff) # Mittelwert der paarweisen Differenzen sd.diff &lt;- sd(anorexia$diff) # Standardabweichung der paarweisen Differenzen n.diff &lt;- length(anorexia$diff) # Stichprobenumfang ermitteln SE.diff &lt;- sd.diff/sqrt(n.diff) # Standardfehler berechnen t.CI &lt;- abs(qt(alpha / 2, df = n.diff - 1)) # t für CI-Berechnung bestimmen CI.diff &lt;- mean.diff + c(-1, 1) * t.CI * SE.diff # CI Grenzen berechnen CI.diff &lt;- round(CI.diff, 3) # CI-Grenzen auf drei Stellen runden CI.output &lt;- paste((1 - alpha) * 100, &quot;%-CI [&quot;, CI.diff[1], &quot;, &quot;, CI.diff[2], &quot;]&quot;) CI.output ## [1] &quot;95 %-CI [ 1.631 , 4.969 ]&quot; ## p-Wert bestimmen t &lt;- (mean.diff - 0) / SE.diff p &lt;- 2 * pt(-abs(t), df = n.diff - 1) t &lt;- round(t, 4) p &lt;- round(p, 4) result &lt;- paste(&quot;t = &quot;, t, &quot;, p = &quot;, p, sep = &quot;&quot;) print(result) ## [1] &quot;t = 4.1917, p = 0.0007&quot; Ergebnis in allgemein verständlicher Sprache formulieren: Die Therapie führt bei anorektischen Patientinnen im Durchschnitt zu einer signifikanten Gewichtszunahme von 3.3 kg 95 %-CI [ 1.631 , 4.969 ], \\(t\\) = 4.1917, \\(df\\) = 16, \\(p\\) = 0.0007 Einfacher geht es mit der R-Funktion t.test(). t.test(anorexia$nach, anorexia$vor, paired = TRUE) ## ## Paired t-test ## ## data: anorexia$nach and anorexia$vor ## t = 4.2, df = 16, p-value = 0.0007 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 1.631 4.969 ## sample estimates: ## mean of the differences ## 3.3 6.1.4 t-Test für unabhängige Stichproben Der \\(t\\)-Test dient der Prüfung von Mittelwertsdifferenzen zweier unabhängiger Stichproben (Unterschiedliche Beobachtungseinheiten, z.B. Vergleich von zwei Gruppen). Parameter: \\(\\mu_1 - \\mu_2\\), z.B. Differenz der Mittelwerte von zwei Populationen Punktschätzer: \\(\\bar{x}_1 - \\bar{x}_2\\) z.B. Differenz der Mittelwerte von zwei Stichproben Teststatistik: \\(t\\) Hypothesen: \\(H_0: \\mu_1 = \\mu_2\\) bzw. \\(H_0: \\mu_1 - \\mu_2 = 0\\) \\(H_A: \\mu_1 \\neq \\mu_2\\) bzw. \\(H_A: \\mu_1 - \\mu_2 \\neq 0\\) (zweiseitige \\(H_A\\)) Signifikanzniveau \\(\\alpha\\) festlegen (meist \\(\\alpha\\) = 0.05). Voraussetzungen (Normalverteilung, Stichprobenumfang) für Testwahl prüfen. Daten stammen aus zwei unabhängigen Zufallsstichproben. Die Daten in beiden Zufallsstichproben sind annähernd normalverteilt. (1-\\(\\alpha\\))-Konfidenzintervall für Populationsparameter berechnen. \\[\\begin{equation} CI_{1-\\alpha} = (\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\frac{\\alpha}{2},df} \\times SE_{\\bar{x}_1 - \\bar{x}_2} \\tag{6.10} \\end{equation}\\] \\[\\begin{equation} df = n_1 + n_2 - 2 \\tag{6.11} \\end{equation}\\] # t für Berechnung des CI in R berechnen t &lt;- abs(qt(alpha/2), df = n1 + n2 - 2) \\(SE\\) vereinfacht (für Berechnungen von Hand) \\[\\begin{equation} SE_{\\bar{x}_1 - \\bar{x}_2} = \\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}} = \\sqrt{SE^2_{\\bar{x}_1} + SE^2_{\\bar{x}_2}} \\tag{6.12} \\end{equation}\\] Gepoolte Standardabweichung \\[\\begin{equation} s_{pooled} = \\sqrt{\\frac{(n_1-1) \\cdot s_1^2+(n_2-1) \\cdot s_2^2}{n_1+n_2-2}}$ \\tag{6.13} \\end{equation}\\] \\(SE\\) für eine Mittelwertsdifferenz \\[\\begin{equation} SE_{\\bar{x}_1 - \\bar{x}_2} = s_{pooled} \\cdot \\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}} \\tag{6.14} \\end{equation}\\] Teststatistik berechnen. \\[\\begin{equation} t = \\frac{\\bar{x}_1 - \\bar{x}_2}{SE_{\\bar{x}_1 - \\bar{x}_2}} \\tag{6.15} \\end{equation}\\] \\(p\\)-Wert für die Teststatisik berechnen. # p-Wert für eine zweiseitige Hypothese 2 * (1 - pt(abs(t), df = n1 + n2 - 2)) # alternativ 2 * pt(-abs(t), df = n1 + n2 - 2) 2 * pt(abs(t), , df = n1 + n2 - 2, lower.tail = FALSE) \\(p\\)-Wert mit Signifikanzniveau vergleichen und Entscheiden ob man \\(H_0\\) verwirft oder beibehält. Ist der \\(p\\)-Wert kleiner als das Signifikanzniveau \\(\\alpha\\), wird die \\(H_0\\) zu Gunsten der \\(H_A\\) verworfen. Ergebnis in allgemein verständlicher Sprache formulieren. Beispiel: Unterscheiden sich Studierende, die mit der Methode A lernen in ihrem Gesamtscore von Studierenden, die mit der Methode B lernen? # Simulierte Daten erzeugen ---------------------------------------------------- set.seed(1) score &lt;- data.frame( ID = seq(from = 1, to = 15, by = 1), methode_A = rnorm(15, mean = 71.5, sd = 9.4), methode_B = rnorm(15, mean = 84.7, sd = 8.3) ) # Kennzahlen ------------------------------------------------------------------- library(dplyr) score %&gt;% summarise( mean.A = mean(methode_A), sd.A = sd(methode_A), mean.B = mean(methode_B), sd.B = sd(methode_B) ) %&gt;% kbl(digits = 2) %&gt;% kable_styling(full_width = FALSE) mean.A sd.A mean.B sd.B 72.45 9.57 85.23 7.1 # Verteilung der beiden Variablen prüfen par(mfrow = c(1, 2)) qqnorm(score$methode_A, main = &quot;QQ-Plot Methode A&quot;) qqline(score$methode_A) qqnorm(score$methode_B, main = &quot;QQ-Plot Methode B&quot;) qqline(score$methode_B) par(mfrow = c(1, 1)) # 95%-CI Grenzen berechnen ----------------------------------------------------- alpha &lt;- .05 m.A &lt;- mean(score$methode_A) s.A &lt;- sd(score$methode_A) n.A &lt;- length(score$methode_A) m.B &lt;- mean(score$methode_B) s.B &lt;- sd(score$methode_B) n.B &lt;- length(score$methode_B) SE &lt;- sqrt(s.A^2/n.A + s.B^2/n.B) df &lt;- n.A + n.B - 2 CI &lt;- (m.B - m.A) + c(-1, 1) * abs(qt(alpha/2, df)) * SE CI &lt;- round(CI, 2) CI.output &lt;- paste((1 - alpha) * 100, &quot;%-CI [&quot;, CI[1], &quot;, &quot;, CI[2], &quot;]&quot;) CI.output ## [1] &quot;95 %-CI [ 6.48 , 19.09 ]&quot; # p-Wert bestimmen t &lt;- (m.A - m.B)/SE p &lt;- 2 * pt(-abs(t), df = df) t &lt;- round(t, 4) p &lt;- round(p, 5) result &lt;- paste(&quot;t = &quot;, t, &quot;, p = &quot;, p, sep = &quot;&quot;) print(result) ## [1] &quot;t = -4.1552, p = 0.00028&quot; Ergebnis in allgemein verständlicher Sprache formulieren: Die Studierenden, die mit der Methode B lernen, erzielen im Durchschnitt einen um 12.784, 95 %-CI [ 6.48 , 19.09 ] signifikant höheren Score als die Studierenden, die mit der Methode A lernen, \\(t\\) = -4.1552, \\(df\\) = 28, \\(p\\) = 0.0003. Einfacher geht es in R mit der Funktion t.test(). Hinweis: Es existieren zwei Varianten des \\(t\\)-Test für unabhängige Stichproben: \\(t\\)-Test für zwei Stichproben mit gleichen Varianzen. Die oben gezeigten Formeln sind für diese Testvariante gültig. \\(t\\)-Test für zwei Stichproben mit ungleichen Varianzen (\\(Welch\\)-Test). Dieser Test führt einen Korrekturfaktor ein der v.a. die Anzahl Freiheitsgrade beeinflusst. Der \\(Welch\\)-Test wird in R standardmässig durchgeführt und ich empfehle, immer diese Testvariante zu verwenden. \\(t\\)-Test für unabhängige Stichproben mit ungleichen Varianzen: Welch-Test \\[\\begin{equation} t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{\\hat{\\sigma}_1^2}{n_1} + \\frac{\\hat{\\sigma}_2^2}{n_2}}} \\tag{6.16} \\end{equation}\\] \\[\\begin{equation} df = \\frac{(n_1-1) \\cdot (n_2-1)}{(n_2-1) \\cdot c^2 + (n_1-1) \\cdot (1-c)^2} \\tag{6.17} \\end{equation}\\] \\[\\begin{equation} c = \\frac{\\frac{\\hat{\\sigma}_1^2}{n_1}}{\\frac{\\hat{\\sigma}_1^2}{n_1}+\\frac{\\hat{\\sigma}_2^2}{n_2}} \\tag{6.18} \\end{equation}\\] # t-Test für gleiche Varianzen t.test(score$methode_B, score$methode_A, var.equal = TRUE) ## ## Two Sample t-test ## ## data: score$methode_B and score$methode_A ## t = 4.2, df = 28, p-value = 0.0003 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 6.482 19.086 ## sample estimates: ## mean of x mean of y ## 85.23 72.45 # t-Test für ungleiche Varianzen, R-standard = Welch-Test t.test(score$methode_B, score$methode_A) ## ## Welch Two Sample t-test ## ## data: score$methode_B and score$methode_A ## t = 4.2, df = 26, p-value = 0.0003 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 6.458 19.110 ## sample estimates: ## mean of x mean of y ## 85.23 72.45 6.2 Nicht-parametrische Testverfahren Nichtparametrische Tests kommen zur Anwendung, wenn die Annahme der Normalverteilung fraglich ist. Für die Anwendung von nichtparametrischen Tests ist es unerheblich, aus welcher Art von Verteilung die Daten stammen. Deshalb werden diese Prüfverfahren auch als verteilungsfreie Verfahren bezeichnet. Die minimale Voraussetzung ist, dass die Prüfvariable mindestens qualitativ-ordinal skaliert ist. Übersicht zur Testwahl Eine Stichprobe \\(\\rightarrow\\) Vorzeichentest Zwei Stichproben verbundene (abhängige) Stichproben \\(\\rightarrow\\) Wilcoxon-Vorzeichenrangtest, Vorzeichentest unabhängige Stichproben \\(\\rightarrow\\) Mann-Whitney-U-Test 6.2.1 Vorzeichentest Referenzen: King and Eckersley (2019) Der Einstichproben-Test: Vergleicht einen Median (\\(\\tilde{x}\\)) mit einem vorgegebenen Referenzmedian. \\(H_0: \\tilde{x} = Nullwert\\). Prüfgrösse sind die Stichprobendaten. Vorgehen: Vergleiche jeden Wert in der Stichprobe mit dem Nullwert. Für Werte die grösser als der Nullwert sind, schreibe ein \\(+\\), für Werte die kleiner als der Nullwert sind, schreibe ein \\(-\\). Zähle die Anzahl \\(+\\) und \\(-\\). Berechne anhand der Regeln für die Binomialverteilung die Wahrscheinlichkeit für dieses oder ein extremeres Resultat unter der Annahme, dass die Nullhypothese zutrifft. Dies ist auch unsere Teststatistik! Wenn \\(p\\) die Wahrscheinlichkeit für einen Erfolg ist, ist \\(1-p\\) die Wahrscheinlichkeit für einen Misserfolg. \\(n\\) gibt die Anzahl der Versuche an und \\(k\\) die Anzahl der Erfolge. \\[\\begin{equation} p(k, n) = {n \\choose k}p^k(1-p)^{n-k} \\tag{6.19} \\end{equation}\\] Vergleiche den p-Wert mit dem Signifikanzniveau. Beachte: Für eine zweiseitige \\(H_A\\) muss der p-Wert verdoppelt werden. Beispiel: In einer neuen Produktionslinie soll die Kontamination eines Produkts mit Schadstoffen unter einem Grenzwert von 50 Einheiten liegen. Gemessen wurde die Kontamination an einer Stichprobe \\(n\\) = 10. \\(H_0: \\tilde{x} = 50\\), der Median der Stichprobe ist 50 \\(H_A: \\tilde{x} &lt; 50\\), der Median der Stichprobe ist kleiner als 50 # Für diesen Code müssen folgende Bibliotheken geladen werden ------------------ # library(dplyr) # library(knitr) # library(kableExtra) ## Kontaminationsdaten --------------------------------------------------------- contamination &lt;- tibble( value = c(45.344, 48.655, 36.199, 54.881, 49.287, 49.336, 53.492, 40.702, 46.318, 31.303) ) nullvalue &lt;- 50 ## Differenz zum Nullwert plus oder minus -------------------------------------- contamination &lt;- contamination %&gt;% mutate( diff = value - nullvalue, sign = if_else(diff &gt;= 0, &quot;plus&quot;, &quot;minus&quot;) ) contamination %&gt;% kbl() %&gt;% kable_styling(full_width = FALSE) value diff sign 45.34 -4.656 minus 48.66 -1.345 minus 36.20 -13.801 minus 54.88 4.881 plus 49.29 -0.713 minus 49.34 -0.664 minus 53.49 3.492 plus 40.70 -9.298 minus 46.32 -3.682 minus 31.30 -18.697 minus ## Summe der positiven und negativen Differenzen ------------------------------- contamination %&gt;% group_by(sign) %&gt;% summarise( n = n() ) %&gt;% kbl() %&gt;% kable_styling(full_width = FALSE) sign n minus 8 plus 2 ## Wie gross ist die Wahrscheinlichkeit 8 oder mehr negative aus 10 zu ziehen p.Wert &lt;- dbinom(8, 10, .5) + dbinom(9, 10, .5) + dbinom(10, 10, .5) ## Tabelle für Resultat erstellen ---------------------------------------------- cont.result &lt;- tibble( Nr.successes = 8, Nr.trials = 10, p.H0 = .5, p.Value = round(p.Wert, 4) ) cont.result %&gt;% kbl(caption = &quot;Vorzeichentest&quot;) %&gt;% kable_styling(full_width = FALSE) Table 6.1: Vorzeichentest Nr.successes Nr.trials p.H0 p.Value 8 10 0.5 0.0547 # Einfacher geht es mit R binom.test(8, 10, .5, alternative = &quot;greater&quot;) ## ## Exact binomial test ## ## data: 8 and 10 ## number of successes = 8, number of trials = 10, p-value = 0.05 ## alternative hypothesis: true probability of success is greater than 0.5 ## 95 percent confidence interval: ## 0.4931 1.0000 ## sample estimates: ## probability of success ## 0.8 Ergebnis in allgemein verständlicher Sprache formulieren: Der kritische Wert für unsere Teststatistik ist das Signifikanzniveau \\(\\alpha\\). Ist der \\(p-Wert\\) grösser als \\(\\alpha\\), haben wir keine Evidenz dafür, dass wir die Nullhypothese verwerfen können. Es liegt nicht ausreichend Evidenz dafür vor, dass der Median der Kontamination signifikant tiefer ist, als der vorgegebene Grenzwert. Der Vorzeichentest kann auch als Wilcoxon Vorzeichenrangtest mit dem Parameter mu = nullvalue durchgeführt werden. Das Resultat ist annähernd das selbe. wilcox.test(x, mu = Nullwert) # Wilcoxon-Vorzeichenrangtest wilcox.test(x = contamination$value, mu = nullvalue, alternative = &quot;less&quot;) ## ## Wilcoxon signed rank exact test ## ## data: contamination$value ## V = 11, p-value = 0.05 ## alternative hypothesis: true location is less than 50 6.2.2 Wilcoxon-Vorzeichenrangtest Quellen: Leonhart (2013), Mi et al. (2022) Wilcoxon Vorzeichenrang-Test für gepaarte Daten: \\(H_0: \\tilde{x}_{\\Delta} = 0\\), Prüfgrösse \\(\\tilde{x}_{\\Delta}\\) = Paarweise Differenzen Stichprobe B minus Stichprobe A. Voraussetzungen: quantitative oder ordinal skalierte Daten unabhängige Beobachtungseinheiten Daten sind annähernd symmetrisch um den Median verteilt. Vorgehen: Paarweise Differenzen nach Grösse sortieren. Die Vorzeichen werden für die Rangbildung ignoriert, das Vorzeichen wird notiert. Rangsummen für positive und negative Differenzen bilden. \\[T_+ = \\sum Ränge ~mit ~positivem ~Vorzeichen\\] \\[T_- = \\sum Ränge ~mit ~negativem ~Vorzeichen\\] Die Teststatistik \\(T\\) ist die kleinere der beiden Rangsummen. Kritischen Wert \\(T_{krit}\\) in Vorzeichen-Rang-Tabelle nachschlagen. Wenn \\(T &lt; T_{krit}\\) wird \\(H_0\\) verworfen. Normalapproximation Für grössere Stichproben (Faustregel: \\(n &gt; 25\\), je nach Autor etwas andere Angaben) ist \\(T\\) annähernd normalverteilt. \\[\\begin{equation} E(T) = \\mu_T = \\frac{n \\times (n + 1)}{4} \\tag{6.20} \\end{equation}\\] \\[\\begin{equation} \\sigma_T^2 = \\frac{n \\times (n + 1) \\times (2n + 1)}{24} \\tag{6.21} \\end{equation}\\] Korrektur für Bindungen Wenn mehrere Bindungen vorliegen, ist ein besserer Schätzer für die Varianz \\[\\begin{equation} \\sigma^2 = \\frac{n \\times (n + 1) \\times (2n + 1)}{24} - \\frac{1}{48} \\sum_t(f_t^3 - f_t) \\tag{6.22} \\end{equation}\\] wobei: \\(t\\) = Anzahl Sets von Bindungen \\(f_t\\) = Häufigkeit von Rang \\(t\\) Teststatistik \\[\\begin{equation} z = \\frac{T - \\mu_T}{\\sigma_T} \\tag{6.23} \\end{equation}\\] Die Approximation einer diskreten Verteilung mittels einer kontinuierlichen Verteilung kann bei \\(n\\) &lt; 60 durch eine Kontinuitätskorrektur bei der Berechnung von \\(z\\) berücksichtigt werden: \\[\\begin{equation} z = \\frac{|T - \\mu_T|-.5}{\\sigma_T} \\tag{6.24} \\end{equation}\\] Beispiel: Zur Überprüfung einer neuen Unterrichtsmethode wurde in einer abhängigen Stichprobe vor und nach einem Sommerlager die Leistung im Fach Statsitik erhoben. Während des Ferienaufenthalts fand ein integrierter Nachhilfekurs in Statistik statt. Die Messung der Statsitikleistung ist im Datensatz prfg gespeichert. # Für diesen Code müssen folgende Bibliotheken geladen werden ------------------ # library(dplyr) # library(knitr) # library(kableExtra) ## Prüfergebnisse -------------------------------------------------------------- prfg &lt;- tibble( ID = seq(from = 1, to = 10, by = 1), vorher = c(22, 26, 12, 20, 22, 26, 22, 24, 40, 40), nachher = c(40, 22, 28, 30, 16, 38, 24, 32, 20, 26) ) ## Paarweise Differenzen berechnen --------------------------------------------- prfg &lt;- prfg %&gt;% mutate( diff = nachher - vorher ) ## Nach Rängen sortieren ------------------------------------------------------- prfg &lt;- prfg %&gt;% mutate( rang = rank(abs(diff)) ) ## Rangsummen für T berechnen -------------------------------------------------- T.plus &lt;- prfg %&gt;% filter(diff &gt; 0) %&gt;% summarise( value = sum(rang) ) T.minus &lt;- prfg %&gt;% filter(diff &lt; 0) %&gt;% summarise( value = sum(rang) ) ## Testgrösse ist das kleinere T ----------------------------------------------- T &lt;- min(T.plus$value, T.minus$value) ## p-Wert berechnen ------------------------------------------------------------ p &lt;- 2 * psignrank(T, n = length(prfg$diff)) ## Tabelle für Output erstellen ------------------------------------------------ prfg.result &lt;- tibble( T.plus = T.plus$value, T.minus = T.minus$value, T = T, T.krit = 8, p.Wert = p ) ## Tabelle anzeigen ------------------------------------------------------------ # library(knitr) # library(kableExtra) prfg.result %&gt;% kbl(digits = 3, caption = &quot;Wilcoxon Vorzeichenrangtest&quot;) %&gt;% kable_styling(full_width = FALSE) Table 6.2: Wilcoxon Vorzeichenrangtest T.plus T.minus T T.krit p.Wert 33 22 22 8 0.625 ## Überprüfung mit wilcox.test() ----------------------------------------------- wilcox.test(prfg$vorher, prfg$nachher, paired = TRUE, correct = FALSE) ## ## Wilcoxon signed rank exact test ## ## data: prfg$vorher and prfg$nachher ## V = 22, p-value = 0.6 ## alternative hypothesis: true location shift is not equal to 0 Anmerkungen Es wird im Beispiel keine Kontinuitätskorrektur oder eine Korrektur für Bindungen verwendet. \\(T.krit\\) wurde manuell der Wilcoxon Vorzeichenrang-Tabelle entnommen (\\(n\\) = 10). Der p-Wert wurde mit der Funktion psignrank(T, n = n) berechnet. Der berechnete \\(T\\)-Wert muss gleich oder kleiner als der kritische \\(T\\)-Wert sein, damit ein signifikanter Unterschied belegt werden kann. In R wird \\(T\\) als \\(V\\) angegeben. Interpretation: Der beobachtete \\(T\\)-Wert unterschreitet den kritischen \\(T\\)-Wert nicht, somit ist der Unterschied zwischen den Testzeitpunkten nicht signifikant und der Sommerkurs hat keinen Effekt auf die Leistung der Schüler:innen in Statistik. 6.2.3 Mann-Whitney-U-Test Referenz: King and Eckersley (2019), Leonhart (2013) Wird auch Wilcoxon Rangsummen-Test genannt. Der U-Test von Mann-Whitney dient dem Vergleich der zentralen Tendenz zweier Stichproben. \\(H_0: P(X &gt; Y) = P(Y &gt; X)\\), m.a.W: Es besteht eine 50%-Wahrscheinlichkeit dafür, dass ein zufällig gezogener Wert aus \\(X\\) grösser ist als ein zufällig gezogener Mittelwert aus \\(Y\\) (und umgekehrt) \\(H_0: P(X &gt; Y) \\neq P(Y &gt; X)\\), m.a.W: Die Wahrscheinlichkeit ist nicht 50%, dass ein zufällig gezogener Wert aus \\(X\\) grösser ist als ein zufällig gezogener Mittelwert aus \\(Y\\) (und umgekehrt) Voraussetzungen quantiative oder ordinal skalierte Daten zwei unabhängige Zufallsstichproben Idee: Die Werte beider Stichproben werden in einer einzige Rangordnung sortiert. Für \\(H_0\\) wird erwartet, dass \\(x &lt; y\\) gleich häufig ist wie \\(y &lt; x\\). Teststatistik \\(U_1\\) und \\(U_2\\) gibt jeweils an, wie viele Rangwerte der anderen Variablen insgesamt niedriger sind. Die Teststatistik \\(U\\) ist der kleinere Wert von den beiden \\(U_1\\) und \\(U_2\\). \\(U_1\\) und \\(U_2\\) werden wie folgt berechnet: \\[\\begin{equation} U_1 = n_1 \\times n_2+\\frac{n_1 \\times (n_1+1)}{2} - T_1 \\tag{6.25} \\end{equation}\\] \\[\\begin{equation} U_2 = n_1 \\times n_2+\\frac{n_2 \\times (n_2+1)}{2} - T_2 \\tag{6.26} \\end{equation}\\] wobei, \\(n_1\\) und \\(n_2\\) die jeweiligen Stichprobenumfänge und \\(T_1\\) und \\(T_2\\) die Rangsummen der Gruppen 1 und 2 sind. Für den Signifikanztest wird nun der kleinere der beiden bestimmten \\(U\\)-Werte verwendet. 2 * (1 - pwilcox(U, m = n1, n = n2, lower.tail = FALSE)) Normalapproximation Für grosse Stichprobenumfänge (\\(n_1\\) oder \\(n_2\\) &gt; 10) ist \\(U\\) annähernd normal verteilt mit: \\[\\begin{equation} E(U) = \\mu_U = \\frac{n_1 \\times n_2}{2} \\tag{6.27} \\end{equation}\\] \\[\\begin{equation} \\sigma_U^2 = \\frac{n_1 \\times n_2 \\times (n_1 + n_2 + 1)}{12} \\tag{6.28} \\end{equation}\\] Teststatistik \\[\\begin{equation} z = \\frac{U - E(U)}{\\sigma_U} \\tag{6.29} \\end{equation}\\] Differieren die beiden Stichprobenumfänge \\(n_1\\) und \\(n_2\\) stark, so empfiehlt sich eine Kontinuitätskorrektur des \\(U\\)-Werts. \\[\\begin{equation} z = \\frac{|U - E(U)|-0.5}{\\sigma_U} \\tag{6.29} \\end{equation}\\] Wenn eine grosse Zahn von verbundenen Rängen vorliegt (zwei Werte in einer Spalte belegen den selben Rang), wird die Standardabweichung von \\(U\\) wie folgt korrigiert: \\[\\begin{equation} \\sigma_{UCorr} = \\sqrt{\\frac{n_1 \\times n_2}{n(n-1)}} \\times \\sqrt{\\frac{n^3-n}{12}-\\sum_{i=1}^k\\frac{t_i^3-t_i}{12}} \\tag{6.30} \\end{equation}\\] wobei \\(n = n_1 + n_2\\) \\(t_i\\) = Anzahl einzelner Werte, welche den Rang \\(i\\) teilen. \\(k\\) = Anzahl gebundene Ränge in R wilcox.test(x, y, alternative = &quot;two.sided&quot;, paired = FALSE) Beispiel: Erreichen Studierende, die während einer Woche täglich 30 Minuten Statistikübungen machen, bessere Noten in einer Statistikprüfung? Für diese Studie wurden 15 Studierende zufällig ausgewählt und zufällig den Gruppen INT (n = 8) und CON (n = 7) zugeteilt. Beide Gruppen besuchten die Statistikvorlesung. Die Studierenden der Gruppe INT machten zusätzlich während einer Woche täglich 30 Min. Statistikübungen, die Gruppe CON machte keine Statistikübungen. Nach einer Woche wurde ein Statistiktest durchgeführt, der mit 0 bis 100 Punkten bewertet wurde. # Für diesen Code müssen folgende Bibliotheken geladen werden ------------------ # library(dplyr) # library(knitr) # library(kableExtra) # Datensatz erstellen ---------------------------------------------------------- statex &lt;- tibble( Gruppe = c(rep(&quot;INT&quot;, 8), rep(&quot;CON&quot;, 7)), Punkte = c(89, 92, 94, 96, 91, 99, 84, 90, 88, 93, 95, 75, 72, 80, 81) ) # Prüfungsergebnisse nach Rängen sortieren statex &lt;- statex %&gt;% mutate( Rang = 16 - rank(Punkte, ties.method = &quot;average&quot; ) ) statex %&gt;% arrange(Rang) %&gt;% kbl(digits = 2, caption = &quot;Statistikresultate mit Rängen&quot;) %&gt;% kable_classic(full_width = FALSE) Table 6.3: Statistikresultate mit Rängen Gruppe Punkte Rang INT 99 1 INT 96 2 CON 95 3 INT 94 4 CON 93 5 INT 92 6 INT 91 7 INT 90 8 INT 89 9 CON 88 10 INT 84 11 CON 81 12 CON 80 13 CON 75 14 CON 72 15 # Rangsummen berechnen rangsummen &lt;- statex %&gt;% group_by(Gruppe) %&gt;% summarise( Rangsumme = sum(Rang) ) T1 &lt;- rangsummen$Rangsumme[1] # Rangsumme für Gruppe CON T2 &lt;- rangsummen$Rangsumme[2] # Rangsumme für Gruppe INT # U berechnen n1 &lt;- 7 n2 &lt;- 8 U1 &lt;- n1 * n2 + (n1 * (n1 + 1))/2 - T1 U2 &lt;- n1 * n2 + (n2 * (n2 + 1))/2 - T2 U &lt;- min(U1, U2) # p-Wert berechnen p &lt;- 2 * (1 - pwilcox(U, m = n1, n = n2, lower.tail = FALSE)) # Resultat als Tabelle ausgeben result &lt;- tibble( T1 = T1, T2 = T2, n1 = n1, n2 = n2, U1 = U1, U2 = U2, U = U, p = round(p, 4) ) result %&gt;% kbl(digits = 4, caption = &quot;Mann-Whitney-U-Test&quot;) %&gt;% kable_styling() Table 6.3: Mann-Whitney-U-Test T1 T2 n1 n2 U1 U2 U p 72 48 7 8 12 44 12 0.0721 # Vergleich mit wilcox.test() wilcox.test( Punkte ~ Gruppe, data = statex, paired = FALSE, alternative = &quot;two.sided&quot;) ## ## Wilcoxon rank sum exact test ## ## data: Punkte by Gruppe ## W = 12, p-value = 0.07 ## alternative hypothesis: true location shift is not equal to 0 Interpretation: Studierende, die während einer Woche täglich 30 Minunten Statistikübungen machen, erreichten in unserer Studie im Durchschnitt eine um 8.45 Punkte höhere Punktzahl in der Statistikprüfung, Mann-Whitney-U = 12, p = 0.0721. Damit liegt keine Evidenz dafür vor, dass sich die Prüfungsergebnisse im Durchschnitt zwischen den beiden Gruppen unterscheiden. 6.3 Bootstrap-Methode in Bearbeitung Bootstrap-Methoden sind eine Alternative zu nichtparametrischen Tests, wenn die Voraussetzungen für parametrische Tests nicht erfüllt sind. Die Berechnung von Bootstrap-Intervallen und Permutationstests setzt erhebliche Rechenleistung voraus, weshalb diese Methoden erst in jüngerer Zeit Verbreitung finden. 6.3.1 Vorgehen Bootstrapping ist eine Möglichkeit, die Stichprobenverteilung aus einer einzigen Stichprobe annähernd zu ermitteln. Zufallsstichprobe im Umfang \\(n\\) aus der zu untersuchenden Population ziehen. Resampling: \\(B\\) Stichproben im Umfang \\(n\\) aus der Zufallsstichprobe ziehen. Dabei wird nach jedem Zug wieder zurückgelegt, d.h. jede Beobachtungseinheit in der Stichprobe kann mehr als einmal gezogen werden. \\(B\\) hat in der Regel einen Wert von &gt; 10000. Bootstrapvertreilung: Die Bootstrapverteilung einer Kennzahl, z.B. \\(\\bar{x}\\), repräsentiert die Werte, welche die Kennzahl in allen möglichen Resamples angenommen hat, also die Stichprobenverteilung der Kennzahl. set.seed(1234) # simulated data --------------------------------------------------------------- drug &lt;- c(-3.6, -2.8, -1.5, 1.4, 1.8, 2.2, 2.8, 3.6) psych::describe(drug) # 1000 means and medians from 10000samples with replacement -------------------- mean.samples &lt;- vector() for (i in 1:10000){ sample &lt;- sample(drug, size = length(drug), replace = TRUE) mean.samples[i] &lt;- mean(sample) } bootstrap &lt;- tibble( m.samples = mean.samples ) # plot histogram and mean ------------------------------------------------------ ggplot(bootstrap, aes(x = m.samples)) + geom_histogram(fill = &quot;steelblue&quot;) + ggtitle(paste(&quot;bootstrapped means, samples = 10000, M = &quot;, round(mean(bootstrap$m.samples), 4)), subtitle = paste(&quot;original mean = &quot;, round(mean(drug), 4))) # calculate CI ----------------------------------------------------------------- alpha &lt;- 0.05 M &lt;- mean(bootstrap$m.samples) SE &lt;- sd(bootstrap$m.samples) CI &lt;- M + c(-1, 1) * abs(qnorm(alpha/2)) * SE CI # normalise data to represent the nullhypothesis ------------------------------- drug.norm &lt;- drug - mean(drug) # 1000 means from 1000 samples with replacement from normalised data ----------- mean.samples &lt;- vector() for (i in 1:10000){ sample &lt;- sample(drug.norm, size = length(drug.norm), replace = TRUE) mean.samples[i] &lt;- mean(sample) } bootstrap$m.samples.norm &lt;- mean.samples # plot histogram and mean ------------------------------------------------------ ggplot(bootstrap, aes(x = m.samples.norm)) + geom_histogram(fill = &quot;steelblue&quot;, binwidth = .2) + geom_vline(xintercept = -.49, color = &quot;red&quot;) + geom_vline(xintercept = .49, color = &quot;red&quot;) + ggtitle(paste(&quot;bootstrapped means, samples = 10000, M = &quot;, round(mean(bootstrap$m.samples.norm), 4)), subtitle = paste(&quot;boundaries two.sided = &quot;, round(mean(drug), 4))) # calculate p-value ------------------------------------------------------------ M.drug &lt;- mean(drug) pnorm(M.drug) - pnorm(-M.drug) # prob for finding a mean value between -.49 and .49 pnorm(-M.drug) # prob for finding a mean value &lt; -.49 pnorm(M.drug, lower.tail = FALSE) # prob for finding a mean Value &gt; .49 # prob finding a p-value of .49 or more extreme two.sided pnorm(-M.drug) + pnorm(M.drug, lower.tail = FALSE) Example from Frost Hypothesistesting bodyfat &lt;- read_csv(&quot;body_fat.csv&quot;) psych::describe(bodyfat$PercFat) hist(bodyfat$PercFat) # 1000 means and medians from 100000 samples with replacement ------------------ mean.samples &lt;- vector() median.samples &lt;- vector() for (i in 1:100000){ sample &lt;- sample(bodyfat$PercFat, size = length(bodyfat$PercFat), replace = TRUE) mean.samples[i] &lt;- mean(sample) median.samples[i] &lt;- median(sample) } bootstrap &lt;- tibble( m.samples = mean.samples, median.samples = median.samples ) # plot histogram and mean ------------------------------------------------------ ggplot(bootstrap, aes(x = m.samples)) + geom_histogram(fill = &quot;steelblue&quot;) + ggtitle(paste(&quot;bootstrapped means, samples = 100000, M = &quot;, round(mean(bootstrap$m.samples), 4)), subtitle = paste(&quot;original mean = &quot;, round(mean(bodyfat$PercFat), 4))) qqnorm(bootstrap$m.samples) # plot histogram and median ------------------------------------------------------ ggplot(bootstrap, aes(x = median.samples)) + geom_histogram(fill = &quot;steelblue&quot;) + ggtitle(paste(&quot;bootstrapped medians, samples = 100000, Median = &quot;, round(mean(bootstrap$median.samples), 4)), subtitle = paste(&quot;original mean = &quot;, round(median(bodyfat$PercFat), 4))) qqnorm(bootstrap$median.samples) # calculate CI ----------------------------------------------------------------- alpha &lt;- 0.05 M &lt;- mean(bootstrap$m.samples) SE &lt;- sd(bootstrap$m.samples) CI &lt;- M + c(-1, 1) * abs(qnorm(alpha/2)) * SE CI Referenzen "],["inferenz-für-qualitative-daten.html", "Kapitel 7 Inferenz für qualitative Daten 7.1 Hypothesentest für eine Stichprobe 7.2 Vergleich von zwei relativen Häufigkeiten 7.3 Chi-Quadrat-Test 7.4 Fishers exakter Test", " Kapitel 7 Inferenz für qualitative Daten s.a. Kapitel 5.2 \\(p:\\) Stichprobenkennzahl \\(\\hat{p}:\\) Schätzer für den Populationsparameter \\(\\pi:\\) Populationsparameter Alle diese Kennzahlen können Werte zwischen 0 und 1 annehmen. \\[\\begin{equation} \\hat{p} = \\frac{Anzahl~Erfolge}{Anzahl~Versuche} \\tag{7.1} \\end{equation}\\] 7.1 Hypothesentest für eine Stichprobe Hypothesen formulieren: \\(H_0: \\pi = Nullwert ~p_0\\) \\(H_A: \\pi &lt; oder &gt; oder \\neq Nullwert ~p_0\\) Punktschätzer \\(\\hat{p}\\) berechnen. Voraussetzungen prüfen Beobachtungen müssen unabhängig sein. \\(np \\geq 10\\) und \\(n(p-1) \\geq 10\\) (hier \\(p\\) aus der Nullhypothese einsetzen!) Teststatistik \\(z\\) berechnen \\[\\begin{equation} z = \\frac{\\hat{p}-p_0}{SE} = \\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\tag{7.2} \\end{equation}\\] Entscheide und interpretiere im Kontext der Forschungsfrage Verwerfe \\(H_0\\), wenn \\(p \\leq \\alpha\\); die Daten liefern Evidenz gegen \\(H_0\\). Verwerfe \\(H_0\\) nicht, wenn \\(p &gt; \\alpha\\); die Daten liefern keine Evidenz gegen \\(H_0\\). \\(\\hat{p}\\) versus \\(p\\) Berechnung eines Konfidenzintervalls: Falls \\(\\pi\\) unbekannt ist, setzen wir den besten Schätzer \\(\\hat{p}\\) ein. \\[n\\hat{p} \\geq 10; ~n(1-\\hat{p}) \\geq 10\\] \\[\\begin{equation} SE_{\\hat{p}} = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\tag{7.3} \\end{equation}\\] Hypothesentest: Wir testen gegen die Nullhypothese und setzen \\(p\\) aus \\(H_0\\) ein. \\[np \\geq 10; ~n(1-p) \\geq 10\\] \\[\\begin{equation} SE_p = \\sqrt{\\frac{p(1-p)}{n}} \\tag{7.4} \\end{equation}\\] Beispiel: In einer Stichprobe von 100 Schüler:innen einer Schule sind 20 Raucher:innen. Wie gross ist der Anteil an Raucher:innen an dieser Schule? Unterscheidet sich der wahre Anteil an Schüler:innen, die an dieser Schule rauchen von 18%? # Für diesen Code müssen folgende Bibliotheken geladen werden ------------------ # library(dplyr) # library(knitr) # library(kableExtra) # Variablen definieren --------------------------------------------------------- n &lt;- 100 # Anzahl Schülerinnen raucher &lt;- 20 # Anzahl Raucherinnen p.hat &lt;- raucher/n # Schätzer für den Anteil Raucherinnen # 95%-Konfidenzintervall berechnen --------------------------------------------- z &lt;- abs(qnorm(.025)) # z-Wert für 95% CI SE &lt;- sqrt((p.hat * (1 - p.hat)) / n) # SE für CI berechnen CI &lt;- p.hat + c(-1, 1) * z * SE # Grenzen des 95%-CI berechnen # Hypothesentest --------------------------------------------------------------- p0 &lt;- .18 # Nullwert definieren SE.hyp &lt;- sqrt((p0 * (1 - p0)) / n) # SE für Hypothesentest berechnen z.p.hat &lt;- (p.hat - p0)/SE.hyp # Teststatistik berechnen prob &lt;- 2 * pnorm(abs(z.p.hat), lower.tail = FALSE) # Tabelle erstellen ------------------------------------------------------------ result &lt;- tibble( p.hat = p.hat, SE = SE, CI.lo = CI[1], CI.hi = CI[2], SE.hyp = SE.hyp, z = z.p.hat, p = prob ) result %&gt;% kbl(digits = 5, caption = &quot;Anteil Raucher:innen&quot;) %&gt;% kable_styling(full_width = FALSE) Table 7.1: Anteil Raucher:innen p.hat SE CI.lo CI.hi SE.hyp z p 0.2 0.04 0.1216 0.2784 0.03842 0.5206 0.6027 Interpretation: An dieser Schule beträgt der Anteil an Raucher:innen im Durchschnitt 20% [95%-CI 12.2%, 27.8%]. Dieser Anteil unterscheidet sich nicht signifikant vom vermuteten Anteil von 18%, \\(z\\) = 0.521, \\(p\\) = 0.603. 7.2 Vergleich von zwei relativen Häufigkeiten Anwendung des zentralen Grenzwertsatzes \\[\\begin{equation} (\\hat{p}_1-\\hat{p}_2) \\sim N \\lgroup Mittelwert = (p_1-p_2), SE = \\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}} \\rgroup \\tag{7.5} \\end{equation}\\] Hypothesen formulieren: \\(H_0: \\pi_1 = \\pi_2\\) \\(H_A: \\pi_1 &lt; oder &gt; oder \\neq Nullwert ~\\pi_2\\) Punktschätzer \\(\\hat{p}_1\\) und \\(\\hat{p}_2\\) berechnen. Voraussetzungen prüfen Beobachtungen müssen unabhängig sein und aus einer Zufallsstichprobe stammen. \\(np_1 \\geq 10\\) und \\(n(p_1-1) \\geq 10\\) und \\(np_2 \\geq 10\\) und \\(n(p_2-1) \\geq 10\\) Konfidenzintervall berechnen \\[\\begin{equation} SE = \\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}} \\tag{7.6} \\end{equation}\\] \\[\\begin{equation} CI = (\\hat{p}_1 - \\hat{p}_2) \\pm z \\times \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}} \\tag{7.7} \\end{equation}\\] Teststatistik \\(z\\) berechnen \\[\\begin{equation} z = \\frac{(\\hat{p}_1-\\hat{p}_2)}{SE_{pooled}} \\tag{7.8} \\end{equation}\\] \\[\\begin{equation} SE_{pooled} = {\\sqrt{\\frac{\\hat{p}_{pool}(1-\\hat{p}_{pool})}{n_1} + \\frac{\\hat{p}_{pool}(1-\\hat{p}_{pool})}{n_2}}} \\tag{7.6} \\end{equation}\\] \\[\\begin{equation} \\hat{p}_{pooled} = \\frac{Anzahl ~Erfolge}{Anzahl ~Fälle} = \\frac{\\hat{p}_1n_1 + \\hat{p}_2n_2}{n_1 + n_2} \\tag{7.9} \\end{equation}\\] \\[\\begin{equation} \\hat{p}_n = \\frac{Anzahl~Erfolge~in~Stichprobe~n}{n_n} \\tag{7.10} \\end{equation}\\] Zusammengefasst eine lange Formel für \\(z\\): \\[\\begin{equation} z = \\frac{(\\hat{p}_1-\\hat{p}_2)}{\\sqrt{\\frac{\\hat{p}_{pool}(1-\\hat{p}_{pool})}{n_1} + \\frac{\\hat{p}_{pool}(1-\\hat{p}_{pool})}{n_2}}} \\tag{7.11} \\end{equation}\\] Entscheide und interpretiere im Kontext der Forschungsfrage Verwerfe \\(H_0\\), wenn \\(p \\leq \\alpha\\); die Daten liefern Evidenz gegen \\(H_0\\). Verwerfe \\(H_0\\) nicht, wenn \\(p &gt; \\alpha\\); die Daten liefern keine Evidenz gegen \\(H_0\\). Beispiel: Wir vergleichen die Zahlen der Schule mit einer zweiten Schule: Dort wurde eine Zufallsstichprobe von 120 Schüler:innen erhoben, wovon 30 Raucher:innen waren. # Für diesen Code müssen folgende Bibliotheken geladen werden ------------------ # library(dplyr) # library(knitr) # library(kableExtra) # Variablen definieren --------------------------------------------------------- n1 &lt;- 100 p1 &lt;- 20 / 100 n2 &lt;- 120 p2 &lt;- 30 / 120 # 95%-Konfidenzintervall berechnen --------------------------------------------- SE &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2)) z.CI &lt;- abs(qnorm(.025)) CI &lt;- (p1 - p2) + c(-1, 1) * z.CI * SE # Hypothesentest --------------------------------------------------------------- p.pool &lt;- ((p1 * n1) + (p2 * n2))/(n1 + n2) SE.pool &lt;- sqrt(p.pool * (1 - p.pool)/n1 + p.pool * (1 - p.pool)/n2) z &lt;- (p1 - p2)/SE.pool prob &lt;- 2 * pnorm(abs(z), lower.tail = FALSE) # Tabelle für Output ----------------------------------------------------------- result &lt;- tibble( M.diff = p1 - p2, CI.lo = CI[1], CI.up = CI[2], SE.pooled = SE.pool, z = z, p = prob ) result %&gt;% kbl(digits = 4, caption = &quot;Vergleich der Raucheranteile an zwei Schulen&quot;) %&gt;% kable_styling(full_width = FALSE) Table 7.2: Vergleich der Raucheranteile an zwei Schulen M.diff CI.lo CI.up SE.pooled z p -0.05 -0.1602 0.0602 0.0567 -0.8812 0.3782 Interpretation: An Schule 1 liegt der Anteil an Raucher:innen bei 20% und an Schule 2 bei 25%. Damit besteht eine durchschnittliche Differenz von 5% [95%-CI: -16%, 6%] zwischen den beiden Schulen. Dieser Unterschied ist nicht signifikant, \\(z\\) = -0.881, \\(p\\) = 0.378. 7.3 Chi-Quadrat-Test auch Chi-Quadrat-Anpassungstest oder Chi-Quadrat-Unabhängigkeitstest Untersucht, ob eine Zusammenhang zwischen zwei nominal oder ordinal skalierten Variablen besteht. Hypothesen: \\(H_0:\\) Die Zeilen- und Spaltenvariablen sind voneineinander unabhängig. \\(H_A:\\) Die Zeilen- und Spaltenvariablen sind hängen voneinander ab. Voraussetzungen: Es handelt sich um unabhängige Beobachtungen aus Zufallsstichproben. Der \\(\\chi^2\\)-Test darf nur durchgeführt werden, wenn die erwartete Häufigkeit in jeder Zelle mindestens 5 beträgt. Andernfalls Fishers exakten Test durchführen. Die erwartete absolute Häufigkeit ist in jeder Zelle \\(\\geq\\) 1. Bei den Daten handelt es sich um absolute Häufigkeiten. Für jede Zelle der Tabelle muss der erwartete Wert \\(E\\) unter der Nullhypothese berechnet werden. \\[\\begin{equation} E = \\frac{Spaltentotal~\\times~Zeilentotal}{Gesamttotal} \\tag{7.12} \\end{equation}\\] \\(\\chi^2\\)-Teststatistik \\[\\begin{equation} \\chi^2 = \\sum_{i=1}^k \\frac{(O_i-E_i)^2}{E_i} \\tag{7.13} \\end{equation}\\] \\(O:\\) beobachtete absolute Häufigkeiten \\(E:\\) erwartete absolute Häufigkeiten \\(k:\\) Anzahl Zellen \\(\\chi^2\\)-Teststatistik mit Kontinuitätskorrektur nach Yates \\[\\begin{equation} \\chi^2 = \\sum_{i=1}^k \\frac{(|O_i-E_i|-0.5)^2}{E_i} \\tag{7.13} \\end{equation}\\] Die \\(\\chi^2\\)-Verteilung hat nur einen Paramter: \\(df\\) \\[\\begin{equation} df = (R-1) \\times (C-1) \\tag{7.14} \\end{equation}\\] \\(R:\\) Anzahl Zeilen \\(C:\\) Anzahl Spalten Der \\(\\chi^2\\)-Test kann in R einfach mit der Funktion chisq.test() durchgeführt werden. chisq.test() Der kritische Wert für \\(\\chi^2\\) kann in einer Verteilungstabelle abgelesen werden. Bei einer Vierfeldertafel (2 Zeilen und 2 Spalten) ist der Zusammenhang zwischen der Zeilen- und der Kolonnenvariable statistisch signifikant auf dem Niveau von 5% wenn \\(\\chi^2\\) grösser als \\(3.84~ (=1.96^2)\\) ist. Beispiel: Untersucht wurde bei 100 Schüler:innen, ob sie Tictoc verwenden. # Beispielaten generieren tictoc_m &lt;- c(rep(&quot;ja&quot;, 23), rep(&quot;nein&quot;, 29)) tictoc_w &lt;- c(rep(&quot;ja&quot;, 38), rep(&quot;nein&quot;, 10)) geschlecht &lt;- c(rep(&quot;m&quot;, length(tictoc_m)), rep(&quot;w&quot;, length(tictoc_w))) tictoc &lt;- data.frame(Geschlecht = geschlecht, tictoc = c(tictoc_m, tictoc_w)) # Chi-Quadrat-Test, Ergebnis in chisq speichern chisq &lt;- chisq.test(table(tictoc)) # Testergebnis anzeigen chisq ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: table(tictoc) ## X-squared = 11, df = 1, p-value = 0.0007 # Beobachtete Werte anzeigen chisq$observed ## tictoc ## Geschlecht ja nein ## m 23 29 ## w 38 10 # erwartete Werte anzeigen chisq$expected ## tictoc ## Geschlecht ja nein ## m 31.72 20.28 ## w 29.28 18.72 Interpretation: Es besteht ein signifikanter Zusammenhang zwischen zwischen den beiden unabhängigen Variablen Geschlecht und der Verwendung von Tictoc, \\(\\chi^2\\) = 11.379, \\(df\\) = 1, \\(p\\) = 0.0007. 7.4 Fishers exakter Test Wenn die Voraussetzungen des \\(\\chi^2\\)-Tests nicht erfüllt sind, ist der exakte Test nach Fisher durchzuführen. Der exakte Test nach Fisher verwendet die hypergeometrische Verteilung zur Berechnung der Resultate und verwendet keine Teststatistik. Table 7.3: 2 x 2 Kontingenztabelle Rows Col_1 Col_2 Total Row_1 a b a+c Row 2 c d b+d Total a+c b+d N=a+b+c+d \\[\\begin{equation} p = \\frac{(a + b)!(c + d)!(a + c)!(b + d)!}{N!a!b!c!d!} \\tag{7.15} \\end{equation}\\] \\[\\begin{equation} OR = \\frac{\\frac{a}{b}}{\\frac{c}{d}} = \\frac{ad}{bc} \\tag{7.16} \\end{equation}\\] # Beispieldaten generieren ----------------------------------------------------- df &lt;- data.frame(&quot;cured&quot; = c(60, 30), &quot;noncured&quot; = c(10, 25), row.names = c(&quot;treated&quot;, &quot;nontreated&quot;)) df %&gt;% kbl() %&gt;% kable_styling(full_width = FALSE) cured noncured treated 60 10 nontreated 30 25 # Exakten Test nach Fischer durchführen ---------------------------------------- fisher.test(df) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: df ## p-value = 0.0002 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 1.983 13.108 ## sample estimates: ## odds ratio ## 4.93 Interpretation: Es besteht ein signifikanter Zusammenhang zwischen zwischen den beiden unabhängigen Variablen (Behandlung und Behandlungsergebnis), Fishers exakter Test, \\(p\\) = 0.00024, OR = 4.93, 95%-CI [1.98, 13.11]. Die Chance (Odds Ratio) für eine Heilung ist für Patienten, die behandelt werden 4.93 mal höher, als für Patienten, die nicht behandelt werden. in Bearbeitung "],["korrelation-und-lineare-regression.html", "Kapitel 8 Korrelation und lineare Regression 8.1 Korrelation", " Kapitel 8 Korrelation und lineare Regression 8.1 Korrelation Bei der Beurteilung von Korrelationen muss stets das Streudiagramm beurteilt werden! Die Korrelation ist ein standardisiertes Mass für den linearen Zusammenhangs zwischen zwei Variablen. 8.1.1 Korrelationskoeffizient nach Pearson \\(r\\) \\[\\begin{equation} r = \\frac{s_{xy}}{s_x \\times s_y} \\tag{8.1} \\end{equation}\\] \\(s_{xy}\\) bezeichnet die Kovarianz der beiden Variablen \\(X\\) und \\(Y\\): \\[\\begin{equation} s_{xy} = \\frac{1}{n-1} \\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) \\tag{8.2} \\end{equation}\\] Der Korrelationskoeffizient \\(r\\) ist empfindlich gegenüber Ausreissern. 8.1.2 Rangkorrelationskoeffizient nach Spearman Der Rangkorrelationskoeffizient nach Spearman \\(r_s\\) ist robust gegenüber Ausreissern misst den monotonen Zusammenhang zwischen zwei Variablen 8.1.3 Interpretation Korrelationskoeffizienten Wertebereich: \\([-1, ~1]\\), \\(0\\) (kein Zusammenhang) \\(\\pm1\\) (perfekter Zusammenhang) Das Vorzeichen gibt die Richtung des Zusammenhangs an: - (Minus) bedeutet negativer Zusammenhang, + (Plus) bedeutet postitiver Zusammenhang. Faustregel zur Interpretation: -0.8 bis -1: starker negativer Zusammenhang -0.8 bis -0.5: mittlerer negativer Zusammenhang -0.5 bis 0.5: schwacher positiver Zusammenhang 0.5 bis 0.8: mittlerer Zusammenhang 0.8 bis 1: starker Zusammenhang # Korrelationskoeffizient nach Pearson cor(x, y) # Rangkorrelationskoeffizient nach Spearman cor(x, y, method = &quot;spearman&quot;) 8.1.4 Hypothesentest für Korrelationskoeffizienten \\(H_0: \\rho = 0\\), es besteht kein linearer Zusammenhang zwischen zwei Variablen. \\(H_A: \\rho \\neq 0\\), es besteht ein linearer Zusammenhang zwischen zwei Variablen. # Korrelationskoeffizient nach Pearson cor.test(x, y) # Rangkorrelationskoeffizient nach Spearman cor.test Beispiel: Besteht ein Zusammenhang zwischen Temperatur und dem Verkauf von Eiscreme? eis &lt;- tibble( temp = c(9, 15, 18, 22, 28, 30), verkauf = c(4, 6, 11, 15, 17, 18) ) plot(eis$temp, eis$verkauf) cor.test(eis$temp, eis$verkauf) ## ## Pearson&#39;s product-moment correlation ## ## data: eis$temp and eis$verkauf ## t = 8.3, df = 4, p-value = 0.001 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7604 0.9971 ## sample estimates: ## cor ## 0.9721 8.1.5 Vertrauensintervall für Pearsons r Da der Wertebereich für \\(r\\) nicht über [-1, 1] hinausgehen kann, ist ein \\(CI\\) z.B. .9 \\(\\pm\\) 2 annehmen kann, da dies die obere Grenze überschreitet. Die obere Grenze des \\(CI\\) muss in diesem Fall beschnitten werden. Auf diese Weise entstehen asymmetrische CI (s. Beispiel oben) (Cumming 2012). Die Verteilung von \\(r\\) ist nicht normal. Mittels Transformation nach Fisher kann die Verteilung einer Stichprobenkorrelation annähernd in eine Normalverteilung umgewandelt werden (Cumming 2012, Statistics Kingdom). Transformation der Stichprobenkorrelation mittels Fishers Transformation \\[\\begin{equation} r&#39; = \\frac{1}{2} \\cdot ln(\\frac{1 + r}{1 - r}) = arctanh(r) \\tag{8.3} \\end{equation}\\] Standardabweichung der transformierten Korrelation berechnen \\[\\begin{equation} s&#39; = \\frac{1}{\\sqrt{n - 3}} \\tag{8.4} \\end{equation}\\] Konfidenzintervall mittels \\(z\\)-Statistik berechnen \\[\\begin{equation} CI&#39;_{lo} = r&#39; - z_{1-\\alpha/2} \\cdot s&#39; \\tag{8.5} \\end{equation}\\] \\[\\begin{equation} CI&#39;_{up} = r&#39; + z_{1-\\alpha/2} \\cdot s&#39; \\tag{8.6} \\end{equation}\\] Rücktransformation der \\(CI\\)-Grenzen in die Originalskala \\[\\begin{equation} CI_{lo} = \\frac{e^{2 \\cdot CI`_{lo}}-1}{e^{2 \\cdot CI`_{lo}}+1} = tanh(CI&#39;_{lo}) \\tag{8.7} \\end{equation}\\] \\[\\begin{equation} CI_{up} = \\frac{e^{2 \\cdot CI`_{up}}-1}{e^{2 \\cdot CI`_{up}}+1} = tanh(CI&#39;_{up}) \\tag{8.8} \\end{equation}\\] \\(r\\): Korrelationskoeffizient der Stichprobe \\(r&#39;\\): transformierter Korrelationskoeffizient nach Fisher \\(s&#39;\\): approximative Standardabweichung der transformierten Korrelation \\(r&#39;\\) \\(n\\): Stichprobenumfang \\(\\alpha\\): Signifikanzniveau \\(1 - \\alpha\\): Konfidenzniveau \\(CI`_{lo}\\): untere Grenze des Vertrauensintervalls für \\(r&#39;\\) \\(CI`_{up}\\): obere Grenze des Vertrauensintervalls für \\(r&#39;\\) \\(CI_{lo}\\): untere Grenze des Vertrauensintervalls für \\(r\\) \\(CI_{up}\\): obere Grenze des Vertrauensintervalls für \\(r\\) confintr::ci_cor(eis$temp, eis$verkauf, probs = c(.025, .975), method = &quot;pearson&quot;, type = &quot;normal&quot;) ## ## Two-sided 95% normal confidence interval for the true Pearson ## correlation coefficient ## ## Sample estimate: 0.9721 ## Confidence interval: ## 2.5% 97.5% ## 0.7604 0.9971 in Bearbeitung Referenzen "],["varianzanalyse.html", "Kapitel 9 Varianzanalyse 9.1 Einfaktorielle Varianzanalyse", " Kapitel 9 Varianzanalyse ANOVA steht für Varianzanalyse (engl. Analysis of Variance) und wird verwendet um die Mittelwerte von mehr als 2 Gruppen zu vergleichen. Hypothesen \\(H_0: \\mu_1 = \\mu_2 ... = \\mu_n\\) \\(H_A: Die ~Mittelwerte ~sind ~nicht ~alle ~gleich\\) 9.1 Einfaktorielle Varianzanalyse 9.1.1 Quadratsummenzerlegung Bei einer Varianzanalyse wird die Gesamtvarianz (total) der abhängigen Variablen \\(y\\) in die Varianz zwischen den Gruppenmittelwerten (between) und die Varianz zwischen den Messwerten innerhalb der Gruppen (within) zerlegt. \\[\\begin{equation} SS_{total}=SS_{between} + SS_{within} {#eq:anova} \\end{equation}\\] Die Gesamtquadratsumme \\(SS_{total}\\) misst die totale Variabilität der abhängigen Variablen. \\[\\begin{equation} SS_{total} = \\sum_{i=1}^n(y_i-\\bar{y})^2 \\tag{9.1} \\end{equation}\\] \\(y_i:\\) Wert der abhängigen Variablen für jede Beobachtung \\(\\bar{y}:\\) Mittelwert der abhängigen Variablen (sog. grand mean) in Bearbeitung "],["effektgrössen.html", "Kapitel 10 Effektgrössen", " Kapitel 10 Effektgrössen "],["referenzen.html", "Kapitel 11 Referenzen", " Kapitel 11 Referenzen "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
